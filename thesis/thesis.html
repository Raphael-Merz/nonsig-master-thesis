<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Raphael Merz">
<meta name="keywords" content="p value, misinterpretation, automation, automated checks, RegEx, LLMs, BERT">
<meta name="description" content="RULES AND NLP FOR CORRECTING P VALUE MISINTERPRETATIONS">

<title>From Detection to Correction: A Hybrid Rule–NLP Approach to Misinterpretations of Nonsignificant p Values</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="thesis_files/libs/clipboard/clipboard.min.js"></script>
<script src="thesis_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="thesis_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="thesis_files/libs/quarto-html/popper.min.js"></script>
<script src="thesis_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="thesis_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="thesis_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="thesis_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="thesis_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="thesis_files/libs/bootstrap/bootstrap-accd75c2bd871f03c4c02dcc9260e8c4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="thesis_files/libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">

<script src="thesis_files/libs/tabwid-1.1.3/tabwid.js"></script>


  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="_extensions/wjschne/apaquarto/apa.css">
</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">1. Introduction</a>
  <ul class="collapse">
  <li><a href="#misinterpretations-and-criticism-of-p-values" id="toc-misinterpretations-and-criticism-of-p-values" class="nav-link" data-scroll-target="#misinterpretations-and-criticism-of-p-values">1.1 Misinterpretations and Criticism of <em>P</em> Values</a></li>
  <li><a href="#possible-solutions" id="toc-possible-solutions" class="nav-link" data-scroll-target="#possible-solutions">1.2 Possible Solutions</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">2. Methods</a>
  <ul class="collapse">
  <li><a href="#the-three-step-pipeline" id="toc-the-three-step-pipeline" class="nav-link" data-scroll-target="#the-three-step-pipeline">2.1 The Three-Step Pipeline</a></li>
  <li><a href="#validation-process-and-performance-metrics" id="toc-validation-process-and-performance-metrics" class="nav-link" data-scroll-target="#validation-process-and-performance-metrics">2.2 Validation Process and Performance Metrics</a>
  <ul class="collapse">
  <li><a href="#statement-detection" id="toc-statement-detection" class="nav-link" data-scroll-target="#statement-detection">2.2.1 Statement Detection</a></li>
  <li><a href="#sec-statement-classification" id="toc-sec-statement-classification" class="nav-link" data-scroll-target="#sec-statement-classification">2.2.2 Statement Classification</a></li>
  <li><a href="#statement-correction" id="toc-statement-correction" class="nav-link" data-scroll-target="#statement-correction">2.2.3 Statement Correction</a></li>
  </ul></li>
  <li><a href="#sec-software" id="toc-sec-software" class="nav-link" data-scroll-target="#sec-software">2.3 Software</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">3 Results</a>
  <ul class="collapse">
  <li><a href="#sec-detection-accuracy" id="toc-sec-detection-accuracy" class="nav-link" data-scroll-target="#sec-detection-accuracy">3.1 Detection Accuracy</a></li>
  <li><a href="#classification-performance" id="toc-classification-performance" class="nav-link" data-scroll-target="#classification-performance">3.2 Classification Performance</a></li>
  <li><a href="#correction-evaluation" id="toc-correction-evaluation" class="nav-link" data-scroll-target="#correction-evaluation">3.3 Correction Evaluation</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">4 Discussion</a>
  <ul class="collapse">
  <li><a href="#summary-of-key-results" id="toc-summary-of-key-results" class="nav-link" data-scroll-target="#summary-of-key-results">4.1 Summary of Key Results</a></li>
  <li><a href="#limitations-and-challenges" id="toc-limitations-and-challenges" class="nav-link" data-scroll-target="#limitations-and-challenges">4.2 Limitations and Challenges</a></li>
  <li><a href="#implications-and-future-directions" id="toc-implications-and-future-directions" class="nav-link" data-scroll-target="#implications-and-future-directions">4.3 Implications and Future Directions</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5 Conclusion</a></li>
  <li><a href="#achknowledgement" id="toc-achknowledgement" class="nav-link" data-scroll-target="#achknowledgement">Achknowledgement</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="thesis.pdf"><i class="bi bi-file-pdf"></i>PDF (apaquarto)</a></li><li><a href="thesis.pdf"><i class="bi bi-file-pdf"></i>Typst (apaquarto)</a></li><li><a href="thesis.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">




<br>

<br>

<section id="title" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">From Detection to Correction: A Hybrid Rule–NLP Approach to Misinterpretations of Nonsignificant <em>p</em> Values</h1>
<div class="Author">
<br>

<p>Raphael Merz</p>
<p>Department of Psychology, Ruhr University Bochum</p>
</div>
<br>

<br>

</section>
<section id="author-note" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Author Note</h1>
<p>Raphael Merz <img src="_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg" id="orchid" class="img-fluid" style="width:4.23mm" alt="Orcid ID Logo: A green circle with white letters ID"> <a href="https://orcid.org/0000-0002-9474-3379">https://orcid.org/0000-0002-9474-3379</a></p>
<p>Correspondence concerning this article should be addressed to Raphael Merz, Department of Psychology, Ruhr University Bochum, Bochum, Germany, Email: raphael.merz@rub.de</p>
</section>
<section id="abstract" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Abstract</h1>
<div class="AbstractFirstParagraph">
<p>Misinterpretations of <em>p</em> values remain widespread in scientific reporting, despite decades of educational efforts and reform initiatives. One of the most common and consequential errors is interpreting a statistically nonsignificant result (e.g., <em>p</em> &gt; .05) as evidence for the absence of an effect — a conclusion not supported by null hypothesis significance testing (NHST). This thesis adopts a human factors perspective, arguing that automation can help mitigate such persistent errors, much like word processors assist with grammar and spelling. I propose an automated, three-step pipeline that detects, classifies, and optionally corrects misinterpretations of nonsignificant results. The evaluation of each of these steps highlights the promise of such an automated approach: In a validation set of 25 articles the automatic detection identified 73% of manually extracted statements. Two easily resolvable issues in the search pattern were found which, once addressed, would increase this reliability to 93%. For classification, three BERT-based models were trained on 930 hand-labeled statements. All models performed well, with the standard BERT model achieving the highest macro F1 score of .92. Finally, the optional correction step proved effective in a validation set 100 statements: 93 statements were correctly phrased after LLM-based revision. These results demonstrate that automation can effectively address this specific misinterpretation and offer a flexible foundation for tackling similar issues in scientific writing and meta-research.</p>
</div>
<p><em>Keywords</em>: p value, misinterpretation, automation, automated checks, RegEx, LLMs, BERT</p>
</section>
<section id="firstheader" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">From Detection to Correction: A Hybrid Rule–NLP Approach to Misinterpretations of Nonsignificant <em>p</em> Values</h1>
</section>
<section id="introduction" class="level1">
<h1>1. Introduction</h1>
<p>Over the past decades, numerous articles have addressed common misinterpretations of <em>p</em> values in the context of standard null hypothesis significance testing <span class="citation" data-cites="goodman08 greenland_etal16 schervish96">(NHST; <a href="#ref-goodman08" role="doc-biblioref">Goodman, 2008</a>; <a href="#ref-greenland_etal16" role="doc-biblioref">Greenland et al., 2016</a>; <a href="#ref-schervish96" role="doc-biblioref">Schervish, 1996</a>)</span>. Some go further, questioning the use of frequentist methods altogether <span class="citation" data-cites="edwards_etal63 wagenmakers07">(<a href="#ref-edwards_etal63" role="doc-biblioref">Edwards et al., 1963</a>; <a href="#ref-wagenmakers07" role="doc-biblioref">Wagenmakers, 2007</a>)</span>, while others propose refinements within the frequentist framework that aim to improve the informativeness of statistical inference <span class="citation" data-cites="isager_fitzgerald25 lakens_etal18">(<a href="#ref-isager_fitzgerald25" role="doc-biblioref">Isager &amp; Fitzgerald, 2025</a>; <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span>. If you are a researcher writing a paper and want to interpret your results correctly, the solution seems simple: read these educational resources and revise your manuscript accordingly. Easy, right? Still, empirical studies consistently show that these misinterpretations remain widespread <span class="citation" data-cites="aczel_etal18 hoekstra_etal06 murphy_etal25">(<a href="#ref-aczel_etal18" role="doc-biblioref">Aczel et al., 2018</a>; <a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>; <a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. So, how might we be able to finally overcome them?</p>
<p>In this article, I show how rule-based approaches, combined with natural language processing (NLP), can be used to automatically detect, classify, and correct these misinterpretations. I focus on the misinterpretation of statistically nonsignificant results as the absence of an effect because it arguably has the strongest impact on researchers’ conclusions and is the most extensively studied misinterpretation of <em>p</em> values <span class="citation" data-cites="lakens21">(<a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. Similarly, my previous work has developed clear criteria for classifying this misinterpretation <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. Here, I demonstrate how this automated approach may help us to resolve them.</p>
<section id="misinterpretations-and-criticism-of-p-values" class="level2">
<h2 data-anchor-id="misinterpretations-and-criticism-of-p-values">1.1 Misinterpretations and Criticism of <em>P</em> Values</h2>
<p>The criticism of <em>p</em> values has become a prominent and recurring theme in discussions around scientific reform. From claims that they encourage dichotomous thinking <span class="citation" data-cites="hoekstra_etal06 amrhein_etal19">(<a href="#ref-amrhein_etal19" role="doc-biblioref">Amrhein et al., 2019</a>; <a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>)</span> to arguments that they offer little informational value <span class="citation" data-cites="wagenmakers07">(<a href="#ref-wagenmakers07" role="doc-biblioref">Wagenmakers, 2007</a>)</span>, <em>p</em> values – and the broader framework of NHST – have been blamed for many of science’s replication problems <span class="citation" data-cites="mcshane_etal19">(e.g.; <a href="#ref-mcshane_etal19" role="doc-biblioref">McShane et al., 2019</a>)</span>. On the other hand, many have also argued that NHST per se is not to blame for these problems, but rather how researchers (mis)use and (mis)interpret this tool <span class="citation" data-cites="greenland19 lakens21">(e.g., <a href="#ref-greenland19" role="doc-biblioref">Greenland, 2019</a>; <a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. As a result, many researchers present whole collections of, in their view, common <em>p</em> value misinterpretations <span class="citation" data-cites="goodman08 greenland_etal16">(see, e.g., <a href="#ref-goodman08" role="doc-biblioref">Goodman, 2008</a>; <a href="#ref-greenland_etal16" role="doc-biblioref">Greenland et al., 2016</a>)</span>.</p>
<p>In this study I zoom in on one specific misinterpretation: concluding <em>no effect</em> based on a statistically nonsignificant finding. Many studies have previously shown that this misinterpretation remains highly prevalent across time and sub-domains of psychology <span class="citation" data-cites="aczel_etal18 hoekstra_etal06">(<a href="#ref-aczel_etal18" role="doc-biblioref">Aczel et al., 2018</a>; <a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>)</span>. In fact, in a recently published article investigating articles published in 2009, 2015, and 2021 across ten different psychology journals, we estimated the prevalence of this misinterpretation in articles’ discussion sections to lie between 76.17% and 84.90% <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. These findings highlight that the situation seems not to have greatly improved despite continuous calls to reflect on statistical interpretations of nonsignificant results <span class="citation" data-cites="altman_bland95 gelman_stern06">(e.g., <a href="#ref-altman_bland95" role="doc-biblioref">Altman &amp; Bland, 1995</a>; <a href="#ref-gelman_stern06" role="doc-biblioref">Gelman &amp; Stern, 2006</a>)</span> and and increasing advocacy for alternative analytical approaches that enable researchers to make informed claims about effects being practically equivalent to zero <span class="citation" data-cites="dienes14 lakens_etal18">(e.g., <a href="#ref-dienes14" role="doc-biblioref">Dienes, 2014</a>; <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span>.</p>
</section>
<section id="possible-solutions" class="level2">
<h2 data-anchor-id="possible-solutions">1.2 Possible Solutions</h2>
<p>One frequently suggested solution is to improve researchers’ statistical literacy through enhanced education, such as better statistics teaching at the undergraduate and graduate levels <span class="citation" data-cites="lakens21">(e.g., <a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. However, as noted earlier, the persistent prevalence of the misinterpretation examined in this study indicates that calls for improved education alone might not have been sufficient to address the issue <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. This is complemented by research showing that many misinterpretations of <em>p</em> values are shared among psychology students and teachers <span class="citation" data-cites="badenes-ribera_etal16 haller_krauss02">(<a href="#ref-badenes-ribera_etal16" role="doc-biblioref">Badenes-Ribera et al., 2016</a>; <a href="#ref-haller_krauss02" role="doc-biblioref">Haller &amp; Krauss, 2002</a>)</span>. Recognizing the limitations of education alone, researchers have also advocated for the use of alternative analysis techniques within the NHST framework, like equivalence testing or minimum-effect tests <span class="citation" data-cites="isager_fitzgerald25">(or the combination: three-sided testing; <a href="#ref-isager_fitzgerald25" role="doc-biblioref">Isager &amp; Fitzgerald, 2025</a>)</span>. These methods allow researchers to test whether an effect is practically relevant and larger than a predefined smallest effect size of interest <span class="citation" data-cites="lakens_etal18">(SESOI; <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span>. In many contexts, such approaches might be more closely aligned with the substantive questions researchers aim to answer, namely whether an effect is negligible or meaningful in practice.</p>
<p>These proposed solutions also align with the argument made by <span class="citation" data-cites="lakens21">Lakens (<a href="#ref-lakens21" role="doc-biblioref">2021</a>)</span> that <em>p</em> value misinterpretations represent a human factors problem, requiring practical and easy-to-implement solutions. In other contexts, we encounter systems like this frequently, be it automatic braking systems in cars, word processors that flag spelling and grammar mistakes, or email clients that filter out malware and phishing attempts. Analogously, automated checks for statistical misinterpretations offer a highly promising route. This perspective emphasizes that many statistical errors arise not from bad intentions or ignorance, but from cognitive limitations and suboptimal workflows.</p>
<p>In the context of research, similar automated solutions are already gaining traction. For instance, the reference manager Zotero flags references to retracted papers <span class="citation" data-cites="stillman19">(<a href="#ref-stillman19" role="doc-biblioref">Stillman, 2019</a>)</span>. Statcheck <span class="citation" data-cites="nuijten_epskamp24">(<a href="#ref-nuijten_epskamp24" role="doc-biblioref">Nuijten &amp; Epskamp, 2024</a>)</span> automatically detects inconsistencies between reported test statistics and <em>p</em> values. Other tools, like GRIM, GRIMMER, and SPRITE, identify impossible values in reported summary statistics <span class="citation" data-cites="heathers_etal18">(<a href="#ref-heathers_etal18" role="doc-biblioref">Heathers et al., 2018</a>)</span>. And lastly, Regcheck <span class="citation" data-cites="cummin_hussey25">(<a href="#ref-cummin_hussey25" role="doc-biblioref">Cummin &amp; Hussey, 2025</a>)</span> verifies the consistency between manuscripts and their preregistration documents. As AI continues to develop, we can expect these types of automated solutions to become increasingly sophisticated and common.</p>
<p>Following this trend, <span class="citation" data-cites="R-papercheck">DeBruine and Lakens (<a href="#ref-R-papercheck" role="doc-biblioref">2025</a>)</span> developed Papercheck, an R package which allows users to run a battery of automated checks on scientific papers. These include statistical checks (e.g., identifying imprecisely reported <em>p</em> values) as well as general manuscript quality checks (e.g., verifying links to online repositories or consistency between in-text citations and reference lists). Papercheck can be used both for single articles (e.g., as writing assistance) and for batches of articles (e.g., for meta-scientific studies). Because this framework is actively maintained and continues to evolve, the approach presented in this study was designed to fit within the Papercheck infrastructure.</p>
</section>
</section>
<section id="methods" class="level1">
<h1>2. Methods</h1>
<section id="the-three-step-pipeline" class="level2">
<h2 data-anchor-id="the-three-step-pipeline">2.1 The Three-Step Pipeline</h2>
<p>To provide context for the data used in this study, I first outline the three sub-steps of the proposed pipeline. Statements from scientific articles need to be reliably detected, classified, and finally, if desired, corrected. For each step, I applied specific methods that were best suited to achieve the respective goal.</p>
<p>To detect statements, I used rule-based regular expressions (RegEx) and searched articles’ results sections to detect these expressions. Effectively, RegEx searchers are advanced Ctrl+F searches, where a user can include rules like optional characters (e.g., ‘significant(ly)’ would catch both <em>significant</em> and <em>significantly</em>) and more complex rules (e.g., ‘not.{0,20}significant’ allows up to 20 characters between <em>not</em> and <em>significant</em>). Papercheck has a module that detects most <em>p</em> values (see <a href="#sec-detection-accuracy" class="quarto-xref">Section&nbsp;3.1</a> in the Results for examples currently not detected) based on RegEx searches. Using this module, I created a subset of all <em>p</em> values equal to or above .05.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> I then expanded the extracted nonsignificant <em>p</em> values to the full sentence and added the preceding and following sentence as context in case of extraction errors (incomplete statements).</p>
<p>In the next step, these statements (labeled as correct or incorrect by me; see <a href="#sec-statement-classification" class="quarto-xref">Section&nbsp;2.2.2</a>) were used to train three BERT-based models. BERT (Bidirectional Encoder Representations from Transformers) is a general-purpose language model pre-trained on the BookCorpus and English Wikipedia, making it suitable for a wide range of tasks – but not specifically optimized for scientific language <span class="citation" data-cites="devlin_etal19">(<a href="#ref-devlin_etal19" role="doc-biblioref">Devlin et al., 2019</a>)</span>. Since its introduction, many researchers have developed domain-specific variants of BERT to enhance its performance on specialized tasks. To test whether such domain adaptation improves performance in this study’s classification task, I trained two models in addition to standard BERT: SciBERT was trained on a large corpus of scientific articles from Semantic Scholar, particularly in the biomedical and computer science domains <span class="citation" data-cites="beltagy_etal19">(<a href="#ref-beltagy_etal19" role="doc-biblioref">Beltagy et al., 2019</a>)</span>. PubMedBERT is an even more specific pretrained language model, having been trained exclusively on biomedical abstracts and full-text articles from the PubMed database <span class="citation" data-cites="gu_etal22">(<a href="#ref-gu_etal22" role="doc-biblioref">Gu et al., 2022</a>)</span>. In this study, these models were trained and evaluated on their ability to distinguish between correct and incorrect interpretations of nonsignificant results in scientific articles. The models’ hyperparameters (e.g., learning rate, batch size) were informed by established defaults in the field (see <a href="https://huggingface.co/docs/transformers/en/main_classes/trainer">Hugging Face Documentation</a>) and relevant tutorials <span class="citation" data-cites="more25 talebi24">(<a href="#ref-more25" role="doc-biblioref">More, 2025</a>; <a href="#ref-talebi24" role="doc-biblioref">Talebi, 2024</a>)</span>, with further refinements to improve the models’ prediction performance.</p>
<p>Lastly, in the application of this framework, statements classified as incorrect by the best-performing BERT model would be sent to a large language model (LLM) for correction. However, to assess how the LLM handles both genuinely incorrect statements and those misclassified as incorrect automatically, I submitted both correct and incorrect statements coded by me to the LLMs in this study.</p>
</section>
<section id="validation-process-and-performance-metrics" class="level2">
<h2 data-anchor-id="validation-process-and-performance-metrics">2.2 Validation Process and Performance Metrics</h2>
<p>To assess the effectiveness of each automated approach, I compared their outputs to human-coded ground truth and calculated appropriate reliability and performance metrics. The validation process was conducted separately for statement detection, classification, and correction.</p>
<section id="statement-detection" class="level3">
<h3 data-anchor-id="statement-detection">2.2.1 Statement Detection</h3>
<p>To ensure that the statement detection process identified all statements with nonsignificant <em>p</em> values in articles’ results sections, I manually extracted these statements from 25 (10%; randomly chosen) of the Papercheck sample library’s 250 open access article from the journal Psychological Science. These articles were published between 2013 and 2024. I then coded whether statements I found were also extracted with the automated RegEx search.</p>
</section>
<section id="sec-statement-classification" class="level3">
<h3 data-anchor-id="sec-statement-classification">2.2.2 Statement Classification</h3>
<p>For the training of the BERT models and to assess their final performance, I classified all automatically extracted statements that were detected from an article’s results section from Papercheck’s sample library. This resulted in 960 statements in total. Of these, 419 were classified as containing a correct <em>p</em> value interpretation by me, and 353 were classified as incorrect <em>p</em> value misinterpretations. The remaining 188 statements were classified as neither correct nor incorrect because they interpreted the nonsignificant effect as (marginally) significant (83), because the statements were not complete enough to check their correctness (20), because they interpreted model fit indices and not the <em>p</em> value (20), because they were falsely flagged as containing a nonsignificant <em>p</em> value (e.g., significant <em>p</em> values or generic ‘<em>p</em> &gt; .05 indicated by symbol ✝’ statements from table/figure notes; 19 in total), or due to a combination of these or other reasons (46).</p>
<p>Before training the model, the labeled data was split into three parts: a test set (20%) for final model evaluation, a training set (72%, or 90% of the remaining 80%) for learning and parameter adjustment, and a validation set (8%, or 10% of the 80%) for calculating evaluation metrics after each epoch (i.e., one full cycle of the model processing the training data) and monitoring overfitting. To address the original class imbalance (with more correct than incorrect statements), the number of correct and incorrect interpretations was balanced in each set, ensuring the model would not simply learn to predict the majority class.</p>
<p>During BERT training, I computed the training loss (sum of errors between model predictions and actual labels in the training set) and the validation loss (calculated analogously on the validation set). The best-performing model was selected based on the lowest validation loss to prevent the model from overfitting to the training data. The model would have been trained on a maximum of 16 epochs, but training ended early if the model did not improve, as measured by the validation loss, for two consecutive epochs. Ultimately, the longest number of training epochs was 7. For the final evaluation, I computed the fraction of correctly predicted classes among all predicted cases of a class (precision), the fraction of correctly predicted classes among all actual cases of a class (recall), and their harmonic mean (F1 score), separately for each class (incorrect and correct). To summarize overall performance across the two classes, I calculated the unweighted average of the two F1 scores (macro-F1 score).</p>
</section>
<section id="statement-correction" class="level3">
<h3 data-anchor-id="statement-correction">2.2.3 Statement Correction</h3>
<p>Lastly, I reviewed 100 statements that were sent to an LLM for correction to evaluate whether the revised statements were correct. Of these, 80 had previously been labeled incorrect and 20 correct by me, allowing me to examine how the LLM would handle false positives from the automated classification. To communicate with the models, I used Papercheck, which relies on the Groq API (available at https://groq.com/). I tested two LLMs – ‘llama-3.3-70b-versatile’ (created 03-09-2023) and ‘openai/gpt-oss-120b’ (created 05-08-2025) – and applied two prompts to the full validation dataset of 100 statements. This resulted in three iterations: (1) the initial prompt with the ‘llama-3.3-70b-versatile’ model, (2) the same prompt with ‘openai/gpt-oss-120b’, and (3) a refined prompt, developed through preliminary tests on subsets of the 100 statements, with ‘openai/gpt-oss-120b’.</p>
<p>Both prompt versions (available on GitHub; see <a href="#sec-software" class="quarto-xref">Section&nbsp;2.3</a>) first explained to the LLM that it would receive a statement containing at least one misinterpretation of a nonsignificant finding as the absence of an effect and instructed it to revise only the part of the statement containing this misinterpretation, leaving the rest unchanged. The refined prompt included additional guidance on phrasing to avoid, based on common errors that persisted in revisions from the initial prompt. Finally, the initial prompt instructed the LLM to indicate when it found no nonsignificant <em>p</em> value or interpretation of it, to account for possible errors during the automatic detection of statements. This instruction was removed in the refined prompt because the LLM overused this option, which blurred the distinction between statement detection, classification, and correction.</p>
</section>
</section>
<section id="sec-software" class="level2">
<h2 data-anchor-id="sec-software">2.3 Software</h2>
<p>All scripts for this study were written in R <span class="citation" data-cites="rcoreteam25">(Version 4.5.0; <a href="#ref-rcoreteam25" role="doc-biblioref">Team, 2025</a>)</span> or Python <span class="citation" data-cites="python">(Version 3.12.10; <a href="#ref-python" role="doc-biblioref">Python Software Foundation, 2025</a>)</span>.</p>
<p>In R, I used <em>papercheck</em> <span class="citation" data-cites="R-papercheck">(Version 0.0.0.9049; <a href="#ref-R-papercheck" role="doc-biblioref">DeBruine &amp; Lakens, 2025</a>)</span> for accessing and preprocessing the 250 open access articles, as well as for communication with the LLMs, <em>readxl</em> <span class="citation" data-cites="R-readxl">(Version 1.4.5; <a href="#ref-R-readxl" role="doc-biblioref">Wickham &amp; Bryan, 2025</a>)</span> to access Excel files in R, <em>psych</em> <span class="citation" data-cites="R-psych">(Version 2.5.6; <a href="#ref-R-psych" role="doc-biblioref">William Revelle, 2025</a>)</span> for calculating descriptive statistics, <em>tidyverse</em> <span class="citation" data-cites="R-tidyverse">(Version 2.0.0; <a href="#ref-R-tidyverse" role="doc-biblioref">Wickham et al., 2019</a>)</span> for data preprocessing and visualization, and <em>flextable</em> <span class="citation" data-cites="R-flextable">(Version 0.9.9; <a href="#ref-R-flextable" role="doc-biblioref">Gohel &amp; Skintzos, 2025</a>)</span>, <em>magick</em> <span class="citation" data-cites="R-magick">(Version 2.8.7; <a href="#ref-R-magick" role="doc-biblioref">Jeroen, 2025</a>)</span>, <em>papaja</em> <span class="citation" data-cites="R-papaja">(Version 0.1.3; <a href="#ref-R-papaja" role="doc-biblioref">Aust &amp; Barth, 2024</a>)</span> and <em>showtext</em> <span class="citation" data-cites="R-showtext">(Version 0.9-7; <a href="#ref-R-showtext" role="doc-biblioref">Qiu &amp; for details., 2024</a>)</span> to create APA-formatted tables and figures.</p>
<p>All scripts and data to reproduce and use the trained BERT models (Python), analyse the results and validity checks (R and Python), recreate this manuscript (Quarto Markdown in R Studio with the apaquarto extension available at: https://wjschne.github.io/apaquarto/), as well as the list of Python libraries used to train the BERT models are available in the following GitHub repository, together with instructions on how to set it up: LINK.</p>
<p>Due to the project’s iterative nature and since no inferential statistical tests were performed, this study was not preregistered. The original project proposal can also be found in the GitHub repository.</p>
</section>
</section>
<section id="results" class="level1">
<h1>3 Results</h1>
<section id="sec-detection-accuracy" class="level2">
<h2 data-anchor-id="sec-detection-accuracy">3.1 Detection Accuracy</h2>
<p>By manually reviewing 25 articles from Papercheck’s sample library, I identified 179 statements containing a nonsignificant <em>p</em> value. The automated RegEx search fully detected 130 (73%) of these, and incompletely detected 6 due to extraction errors, often caused by PDF formatting (page breaks, figures, or footnotes). The search also produced 3 false positives – statements incorrectly labeled as coming from the results section, but actually originating from other sections, or from table or figure notes. Note, however, that most of the 49 (partially) missed statements were due to specific ways of writing (or not writing) the <em>p</em> value: 31 were missed because the <em>p</em> value was written as ‘<span class="math inline">p_s</span>’ (smallest <em>p</em> value in a group of tests), and 8 were missed because the authors wrote ‘n.s.’ instead of the nonsignificant <em>p</em> value. Excluding these two types of reporting, the overall agreement between the automated and manual approaches would have been 93%.</p>
<p>Lastly, the remaining 10 missed statements were due to PDF formatting issues such as figures, tables, footnotes, page breaks, or unusual characters within the statement that interfered with the statement detection (9 in total).<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</section>
<section id="classification-performance" class="level2">
<h2 data-anchor-id="classification-performance">3.2 Classification Performance</h2>
<p><a href="#fig-loss-curves" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a> shows the training and validation loss curves for the three BERT models across their training epochs. The standard BERT model was trained for a total of 7 epochs before early stopping was triggered due to a lack of improvement in validation loss for two consecutive epochs. The model from epoch 5 was therefore selected as the best-performing one. Similarly, SciBERT and PubMedBERT reached the lowest validation loss after epochs 5 and 4, respectively. As shown in the figure, the training loss consistently decreased throughout training for all three models, as expected since the models were optimized to fit the training data. In contrast, the validation loss plateaued in all models before rising again, indicating that further improvements on the training data no longer translated to better performance on the unseen validation data and may signal the onset of overfitting.</p>
<div id="fig-loss-curves" class="quarto-float quarto-figure quarto-figure-center FigureWithNote" data-fignum="1" data-apa-note="Curves of the training and validation loss of the three trained BERT models. The best models for standard BERT, SciBERT and PubMedBERT were chosen after epoch 5, 5, and 4, respectively, based on a minmal validation loss." prefix="" alt="Curves of the training and validation loss of the three trained BERT models. The best models for standard BERT, SciBERT and PubMedBERT were chosen after epoch 5, 5, and 4, respectively, based on a minmal validation loss." data-custom-style="FigureWithNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-loss-curves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Training and Validation Loss Curves</p>
</div>
</figcaption>
<div aria-describedby="fig-loss-curves-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../data/model_performance/loss_curve/loss_combined.png" class="img-fluid figure-img" style="width:6in" data-apa-note="Curves of the training and validation loss of the three trained BERT models. The best models for standard BERT, SciBERT and PubMedBERT were chosen after epoch 5, 5, and 4, respectively, based on a minmal validation loss." alt="Curves of the training and validation loss of the three trained BERT models. The best models for standard BERT, SciBERT and PubMedBERT were chosen after epoch 5, 5, and 4, respectively, based on a minmal validation loss.">
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Curves of the training and validation loss of the three trained BERT models. The best models for standard BERT, SciBERT and PubMedBERT were chosen after epoch 5, 5, and 4, respectively, based on a minmal validation loss.</p>
</div>
<p>With respect to model performance, <a href="#fig-confusion" class="quarto-xref" aria-expanded="false">Figure&nbsp;2</a> displays the number of correctly and incorrectly classified statements for each model. Overall, all three models performed well, with the standard BERT model showing the fewest misclassifications (2 false positives and 9 false negatives), while SciBERT and PubMedBERT made 14 and 21 false classifications in total, respectively. All models also tended to predict more statements as correct than incorrect, despite the originally balanced class distribution: for example, the standard BERT model classified 78 statements as correct and 64 as incorrect, with this difference being even more pronounced in SciBERT (81 vs.&nbsp;61) and especially PubMedBERT (88 vs.&nbsp;54).</p>
<p>These results are further summarized in <a href="#tbl-model-performance" class="quarto-xref" aria-expanded="false">Table&nbsp;1</a>. The standard BERT model achieved the highest macro-F1 score (.92), with SciBERT and PubMedBERT scoring slightly lower (.90 and .85). Across all models, performance was stronger for predicting correct statements than incorrect ones, as indicated by higher F1 scores and recall in the ‘correct’ class. This pattern, again, underlines that the models tended to overidentify statements as correct rather than incorrect.</p>
<div id="fig-confusion" class="quarto-float quarto-figure quarto-figure-center FigureWithNote" data-fignum="2" data-apa-note="Confusion matrices of the three trained BERT models. Overall, the standard BERT model performed best with a macro-F1 score of .92." prefix="" alt="Confusion matrices of the three trained BERT models. Overall, the standard BERT model performed best with a macro-F1 score of .92." data-custom-style="FigureWithNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Confusion Matrices</p>
</div>
</figcaption>
<div aria-describedby="fig-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../data/model_performance/confusion_matrix/confusion_matrix_combined.png" class="img-fluid figure-img" style="width:6.5in" data-apa-note="Confusion matrices of the three trained BERT models. Overall, the standard BERT model performed best with a macro-F1 score of .92." alt="Confusion matrices of the three trained BERT models. Overall, the standard BERT model performed best with a macro-F1 score of .92.">
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Confusion matrices of the three trained BERT models. Overall, the standard BERT model performed best with a macro-F1 score of .92.</p>
</div>
<div class="cell FigureWithNote" data-apa-note="Table of precision, recall and F1 score per model and class." data-ft-align="left" prefix="" data-tblnum="1" data-custom-style="FigureWithNote">
<div id="tbl-model-performance" class="cell quarto-float quarto-figure quarto-figure-center" data-tblnum="1" data-ft-align="left" prefix="" data-apa-note="Table of precision, recall and F1 score per model and class.">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Model Performance</p>
</div>
</figcaption>
<div aria-describedby="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-e176d9fe{}.cl-e16fb2aa{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e17288c2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-e172a6b8{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6b9{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6c2{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6c3{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6c4{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6cc{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6cd{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6ce{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6d6{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6d7{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6e0{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6e1{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6e2{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6ea{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6eb{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e172a6ec{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-e176d9fe"><thead><tr style="overflow-wrap:break-word;"><th class="cl-e172a6b8"><p class="cl-e17288c2"><span class="cl-e16fb2aa"> </span></p></th><th colspan="3" class="cl-e172a6b9"><p class="cl-e17288c2"><span class="cl-e16fb2aa">BERT</span></p></th><th colspan="3" class="cl-e172a6b9"><p class="cl-e17288c2"><span class="cl-e16fb2aa">SciBERT</span></p></th><th colspan="3" class="cl-e172a6b9"><p class="cl-e17288c2"><span class="cl-e16fb2aa">PubMedBERT</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-e172a6c4"><p class="cl-e17288c2"><span class="cl-e16fb2aa"> </span></p></th><th class="cl-e172a6cc"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Precision</span></p></th><th class="cl-e172a6cd"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Recall</span></p></th><th class="cl-e172a6ce"><p class="cl-e17288c2"><span class="cl-e16fb2aa">F1 score</span></p></th><th class="cl-e172a6cc"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Precision</span></p></th><th class="cl-e172a6cd"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Recall</span></p></th><th class="cl-e172a6ce"><p class="cl-e17288c2"><span class="cl-e16fb2aa">F1 score</span></p></th><th class="cl-e172a6cc"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Precision</span></p></th><th class="cl-e172a6cd"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Recall</span></p></th><th class="cl-e172a6ce"><p class="cl-e17288c2"><span class="cl-e16fb2aa">F1 score</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-e172a6d6"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Correct Class</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.88</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.97</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.93</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.85</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.97</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.91</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.78</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.97</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.87</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e172a6d6"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Incorrect Class</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.97</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.87</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.92</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.97</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.83</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.89</span></p></td><td class="cl-e172a6d7"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.96</span></p></td><td class="cl-e172a6e0"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.73</span></p></td><td class="cl-e172a6e1"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.83</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e172a6e2"><p class="cl-e17288c2"><span class="cl-e16fb2aa">Macro F1 score</span></p></td><td class="cl-e172a6ea"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6eb"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6ec"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.92</span></p></td><td class="cl-e172a6ea"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6eb"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6ec"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.90</span></p></td><td class="cl-e172a6ea"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6eb"><p class="cl-e17288c2"><span class="cl-e16fb2aa"></span></p></td><td class="cl-e172a6ec"><p class="cl-e17288c2"><span class="cl-e16fb2aa">.85</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of precision, recall and F1 score per model and class.</p>
</div>
</div>
<p><a href="#tbl-false-classification" class="quarto-xref" aria-expanded="false">Table&nbsp;2</a> shows statements misclassified by all three models to illustrate common sources of difficulty. Potential causes of these misclassifications will be explored in the discussion.</p>
<div class="cell FigureWithNote" data-apa-note="Examples for statements that were incorrectly classified by all three BERT models." data-ft-align="left" prefix="" data-tblnum="2" data-custom-style="FigureWithNote">
<div id="tbl-false-classification" class="cell quarto-float quarto-figure quarto-figure-center" data-tblnum="2" data-ft-align="left" prefix="" data-apa-note="Examples for statements that were incorrectly classified by all three BERT models.">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-false-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Incorrect Model Classifications</p>
</div>
</figcaption>
<div aria-describedby="tbl-false-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-e185dc06{}.cl-e17f3810{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e181c6ca{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-e181e1dc{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e181e1e6{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e181e1e7{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e181e1f0{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e181e1f1{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e181e1f2{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-e185dc06"><thead><tr style="overflow-wrap:break-word;"><th class="cl-e181e1dc"><p class="cl-e181c6ca"><span class="cl-e17f3810">Model Prediction</span></p></th><th class="cl-e181e1e6"><p class="cl-e181c6ca"><span class="cl-e17f3810">Statement</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-e181e1e7"><p class="cl-e181c6ca"><span class="cl-e17f3810">False Negative</span></p></td><td class="cl-e181e1f0"><p class="cl-e181c6ca"><span class="cl-e17f3810">Although the sensitivity for the not-learned set was statistically comparable to the prelearning baseline, t(44) = 1.95, p = .162, d = 0.29, the learned set revealed significantly higher scores compared with both the not-learned set, t(44) = 2.56, p &lt; .04, d = 0.38, and the prelearning set, t(44) = 4.51, p &lt; .001, d = 0.67 (all comparisons performed with Bonferroni correction; see Fig. 3a).</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e181e1e7"><p class="cl-e181c6ca"><span class="cl-e17f3810">False Negative</span></p></td><td class="cl-e181e1f0"><p class="cl-e181c6ca"><span class="cl-e17f3810">However, CS type did not interact significantly with the contrast between the uninformed and random groups; the uninformed group showed no better differentiation than the random group, F(1, 76) = 1.29, p = .26, 95% CI = [-0.16, 0.57].</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e181e1e7"><p class="cl-e181c6ca"><span class="cl-e17f3810">False Negative</span></p></td><td class="cl-e181e1f0"><p class="cl-e181c6ca"><span class="cl-e17f3810">Gender, trait aggression, and endogenous testosterone did not affect these behavioral congruency effects on RTs and accuracy, and aggression and endogenous testosterone were not significantly correlated (r = .046, p = .45).</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e181e1f1"><p class="cl-e181c6ca"><span class="cl-e17f3810">False Positive</span></p></td><td class="cl-e181e1f2"><p class="cl-e181c6ca"><span class="cl-e17f3810">The main effect of illness recency did not meet our preregistered threshold (p &lt; .025)-recently ill: M = 661 ms, SD = 197; not recently ill: M = 626 ms, SD = 153, F(1, 400) = 4.23, Î· p 2 = .010, 90% CI = [.000, .039], p = .040-nor did the interaction between illness recency and face type (disfigured vs. typical), F(1, 400) = 1.87, Î· p 2 = .005, 90% CI = [.000, .027], p = .173.</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Examples for statements that were incorrectly classified by all three BERT models.</p>
</div>
</div>
</section>
<section id="correction-evaluation" class="level2">
<h2 data-anchor-id="correction-evaluation">3.3 Correction Evaluation</h2>
<p>Of the 100 statements that the LLM was instructed to correct 85 were evaluated as correct in the first iteration (initial prompt and older ‘llama-3.3-70b-versatile’ model). Notably, 2 of the 20 already correct statements were turned incorrect by the LLM, and 13 of the 80 incorrect statements remained incorrect. Using the newer ‘openai/gpt-oss-120b’ model, 79 statements were evaluated as correct after LLM-revision. However, the model left 8 correct and 2 incorrect statements unrevised, following instructions in the initial prompt that allowed it to skip statements if it did not find a nonsignificant <em>p</em> value or corresponding interpretation. In the final iteration, with the newer model and revised prompt, 93 of the 100 LLM-revised statements were correct. Of the remaining 7 statements, four (one originally correct and three incorrect) described the results as ‘compatible with effects of exactly or around zero’ – an interpretation that may be technically defensible but still fails to adequately acknowledge the uncertainty in the test result. In one originally correct statement, the LLM removed all <em>p</em> values and described the effect as if they were significant. The remaining two were originally incorrect statements, one of which simply remained incorrect, while the other one was altered to the point that it no longer conveyed the original meaning (originally referring to model fit, which was not clear in the revision). Examples of both poor and strong LLM-revisions from this final iteration are shown in <a href="#tbl-LLM-corrections-1" class="quarto-xref" aria-expanded="false">Table&nbsp;3</a> and <a href="#tbl-LLM-corrections-2" class="quarto-xref" aria-expanded="false">Table&nbsp;4</a>, respectively.</p>
<div class="cell FigureWithNote" data-apa-note="Table of original and LLM-revised statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect." data-ft-align="left" prefix="" data-tblnum="3" data-custom-style="FigureWithNote">
<div id="tbl-LLM-corrections-1" class="cell quarto-float quarto-figure quarto-figure-center" data-tblnum="3" data-ft-align="left" prefix="" data-apa-note="Table of original and LLM-revised statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect.">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-LLM-corrections-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;3</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Examples of Incorrect LLM-Revisions</p>
</div>
</figcaption>
<div aria-describedby="tbl-LLM-corrections-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-e1a3d1de{}.cl-e19cf080{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e19fd19c{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-e19fd1a6{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1.2;background-color:transparent;}.cl-e19fec90{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e19fec9a{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e19fec9b{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e19feca4{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e19feca5{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e19fecae{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-e1a3d1de"><thead><tr style="overflow-wrap:break-word;"><th class="cl-e19fec90"><p class="cl-e19fd19c"><span class="cl-e19cf080">Example</span></p></th><th class="cl-e19fec90"><p class="cl-e19fd19c"><span class="cl-e19cf080">Statement Type</span></p></th><th class="cl-e19fec9a"><p class="cl-e19fd19c"><span class="cl-e19cf080">Statement</span></p></th><th class="cl-e19fec90"><p class="cl-e19fd19c"><span class="cl-e19cf080">Label</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-e19fec9b"><p class="cl-e19fd1a6"><span class="cl-e19cf080">From 0 to 0</span></p></td><td class="cl-e19fec9b"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Original</span></p></td><td class="cl-e19feca4"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Although the PTSD group showed a significant facilitation effect (M = 5.9%), F(1, 15) = 7.525, p = .015, Î· p 2 = .334, and the control group did not (M = 2.8%, n.s.), there was no significant group difference in facilitation, F(1, 30) = 1.215, p = .279, Î· p 2 = .039 (Fig. 3a).</span></p></td><td class="cl-e19fec9b"><p class="cl-e19fd19c"><span class="cl-e19cf080">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e19fec9b"><p class="cl-e19fd1a6"><span class="cl-e19cf080">LLM-revised</span></p></td><td class="cl-e19feca4"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Although the PTSD group showed a significant facilitation effect (M = 5.9 %), F(1, 15) = 7.525, p = .015, ηp² = .334, the control group did not reach statistical significance (M = 2.8 %). The group difference in facilitation was not statistically significant, F(1, 30) = 1.215, p = .279, ηp² = .039 (Fig. 3a).</span></p></td><td class="cl-e19fec9b"><p class="cl-e19fd19c"><span class="cl-e19cf080">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-e19feca5"><p class="cl-e19fd1a6"><span class="cl-e19cf080">From 1 to 0</span></p></td><td class="cl-e19fec9b"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Original</span></p></td><td class="cl-e19feca4"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Cortisol concentrations were comparable at baseline, t(55) = 1.01, p = .317, d = 0.27, but significantly elevated in the stress group relative to the control group both 30 min after the treatment, t(55) = 3.55, p corr = .003, d = 0.94, and 45 min after the treatment, t(55) = 2.52, p corr = .045, d = 0.67 (Table 1).</span></p></td><td class="cl-e19fec9b"><p class="cl-e19fd19c"><span class="cl-e19cf080">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e19feca5"><p class="cl-e19fd1a6"><span class="cl-e19cf080">LLM-revised</span></p></td><td class="cl-e19fecae"><p class="cl-e19fd1a6"><span class="cl-e19cf080">Cortisol concentrations were not significantly different at baseline, t(55) = 1.01, p = .317, d = 0.27, but were significantly elevated in the stress group relative to the control group both 30 min after the treatment, t(55) = 3.55, p corr = .003, d = 0.94, and 45 min after the treatment, t(55) = 2.52, p corr = .045, d = 0.67 (Table 1).</span></p></td><td class="cl-e19feca5"><p class="cl-e19fd19c"><span class="cl-e19cf080">0</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of original and LLM-revised statements that were classified as incorrect. In the examples ‘0’ refers to correct and ‘1’ to incorrect.</p>
</div>
</div>
<div class="cell FigureWithNote" data-apa-note="Table of original and LLM-revised statements that were classified as correct. In the examples '0' refers to correct and '1' to incorrect." data-ft-align="left" prefix="" data-tblnum="4" data-custom-style="FigureWithNote">
<div id="tbl-LLM-corrections-2" class="cell quarto-float quarto-figure quarto-figure-center" data-tblnum="4" data-ft-align="left" prefix="" data-apa-note="Table of original and LLM-revised statements that were classified as correct. In the examples '0' refers to correct and '1' to incorrect.">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-LLM-corrections-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;4</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Examples of Correct LLM-Revisions</p>
</div>
</figcaption>
<div aria-describedby="tbl-LLM-corrections-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-e1b5aac6{}.cl-e1af02d4{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-e1b1a5fc{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-e1b1a606{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1.2;background-color:transparent;}.cl-e1b1bfe2{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1b1bfec{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1b1bff6{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1b1bff7{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1b1c000{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-e1b1c001{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-e1b5aac6"><thead><tr style="overflow-wrap:break-word;"><th class="cl-e1b1bfe2"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">Example</span></p></th><th class="cl-e1b1bfe2"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">Statement Type</span></p></th><th class="cl-e1b1bfec"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">Statement</span></p></th><th class="cl-e1b1bfe2"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">Label</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="4" class="cl-e1b1bff6"><p class="cl-e1b1a606"><span class="cl-e1af02d4">From 1 to 0</span></p></td><td class="cl-e1b1bff7"><p class="cl-e1b1a606"><span class="cl-e1af02d4">Original</span></p></td><td class="cl-e1b1c000"><p class="cl-e1b1a606"><span class="cl-e1af02d4">Non-attraction-effect choices were very rare and, like decoy choices, they likely reflect noisy responding; they were more common among people with lower cognitive ability, b = 0.689, 95% CI = [0.357, 1.021], p &lt; .001, but did not differ between the ASC and control groups, b = -0.037, 95% CI = [-0.381, 0.307], p = .834, and were unrelated to age, b = 0.014, 95% CI = [-0.295, 0.324], p = .929, or gender, b = -0.229, 95% CI = [-0.528, 0.069], p = .132.</span></p></td><td class="cl-e1b1bff7"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e1b1bff7"><p class="cl-e1b1a606"><span class="cl-e1af02d4">LLM-revised</span></p></td><td class="cl-e1b1c000"><p class="cl-e1b1a606"><span class="cl-e1af02d4">Non-attraction-effect choices were very rare and, like decoy choices, they likely reflect noisy responding; they were more common among people with lower cognitive ability (b = 0.689, 95 % CI = [0.357, 1.021], p &lt; .001). The estimated difference between the ASC and control groups was b = ‑0.037 (95 % CI = [‑0.381, 0.307], p = .834). The estimated association with age was b = 0.014 (95 % CI = [‑0.295, 0.324], p = .929), and the estimated association with gender was b = ‑0.229 (95 % CI = [‑0.528, 0.069], p = .132).</span></p></td><td class="cl-e1b1bff7"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e1b1bff7"><p class="cl-e1b1a606"><span class="cl-e1af02d4">Original</span></p></td><td class="cl-e1b1c000"><p class="cl-e1b1a606"><span class="cl-e1af02d4">This preference, however, disappeared in the experimental condition, F(1, 170) = 2.32, p = .130, Î· p 2 = .01.</span></p></td><td class="cl-e1b1bff7"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-e1b1bff6"><p class="cl-e1b1a606"><span class="cl-e1af02d4">LLM-revised</span></p></td><td class="cl-e1b1c001"><p class="cl-e1b1a606"><span class="cl-e1af02d4">In the experimental condition, the preference was not statistically significant, F(1, 170) = 2.32, p = .130, ηp² = .01.</span></p></td><td class="cl-e1b1bff6"><p class="cl-e1b1a5fc"><span class="cl-e1af02d4">0</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of original and LLM-revised statements that were classified as correct. In the examples ‘0’ refers to correct and ‘1’ to incorrect.</p>
</div>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>4 Discussion</h1>
<section id="summary-of-key-results" class="level2">
<h2 data-anchor-id="summary-of-key-results">4.1 Summary of Key Results</h2>
<p>In this study, I developed and evaluated a three-step pipeline for automatically detecting, classifying and correcting misinterpretations of nonsignificant results as evidence for the absence of an effect. The pipeline combines (1) rule-based RegEx searches to identify candidate statements, (2) fine-tuned BERT models to classify them as correct or incorrect, and (3) LLMs to generate revised phrasings. Although clear areas for improvement emerged, each component performed well overall. This demonstrates the potential of hybrid, stepwise approaches for addressing persistent reporting issues in scientific writing, with applications beyond <em>p</em> value misinterpretations.</p>
<p>Each step contributes distinct strengths. The RegEx-based detection offers a fast, systematic, and transparent way of reducing the volume of text needing NLP-based analysis. The BERT classifiers, having been trained on human-annotated data, provide a reliable and powerful solution for identifying subtle language patterns. The final correction step, while optional, shows that LLMs can generate context-sensitive rewordings that may help authors revise problematic statements.</p>
<p>Moving to the sub-steps, the RegEx-based statement detection phase demonstrated that simple, rule-based searches can effectively flag a large proportion of candidate interpretations. Although formatting issues in PDFs made the correct extraction of these misinterpretations impossible in some cases, the vast majority of statements were automatically detected. In addition, this study revealed straightforward issues in the current approach (e.g., <em>p</em> as “p = n.s.” or with subscripted ‘<span class="math inline">p_s</span>’) that can be fixed with minimal adjustments, further enhancing the detection accuracy.</p>
<p>The classification results are particularly promising given the relatively small size of the manually labeled dataset (&lt; 1,000 examples, split into training, validation, and test sets). The strong performance likely reflects a certain regularity in how nonsignificance is (mis)interpreted in academic writing – commonly through the use of either ‘significant’ or ‘no effect’ (e.g., ‘there was no effect’, but also ‘groups did not differ’) terminology. Interestingly, the standard BERT model showed the best overall performance, potentially reflecting that SciBERT’s and PubMedBERT’s more domain-specific knowledge might not have been necessary for the classification of these statements.</p>
<p>Finally, the correction step demonstrated that LLMs can provide useful alternative phrasings to misinterpretations. While further prompt engineering will be necessary to reduce occasional mistakes (especially those turning correct statements into incorrect ones), this step illustrates the potential of integrating generative AI into targeted scientific writing support. Whether such corrections are genuinely valued by authors, however, remains an open question that needs further discussion.</p>
</section>
<section id="limitations-and-challenges" class="level2">
<h2 data-anchor-id="limitations-and-challenges">4.2 Limitations and Challenges</h2>
<p>A key limitation is that the pipeline was tested step by step rather than as a fully integrated system. While detection, classification, and correction each worked well independently, cascading errors are inevitable once these steps are combined. As a result, the overall accuracy in end-to-end use will likely be lower than suggested by isolated evaluations. Nonetheless, any detected misinterpretation should alert authors that their interpretation, some possibly left unflagged, may require reconsideration.</p>
<p>Similarly, the RegEx-based approach proved efficient but also exposed the fragility of rule-based methods when faced with variation in formatting. Cases such as ‘p = n.s.’ or <span class="math inline">p_s</span> were frequently missed. These errors are relatively easy to address through refinements of the pattern set but highlight that rule-based detection will always struggle with rare or novel notations.</p>
<p>Moving on to classification, the step performed strongly overall, but the use of a single annotator introduces subjectivity into the training labels. While I made efforts to standardize labels – often consulting a statistics expert (my supervisor) on difficult or borderline cases – the classifications ultimately reflect my interpretation of what constitutes a misinterpretation. Ideally, multiple annotators and inter-rater agreement metrics would strengthen the reliability and generalizability of the training dataset. However, the fact that the fine-tuned BERT models generalized well to unseen data suggests that the labeling was systematic enough for the models to learn.</p>
<p>The standard BERT model consistently outperformed the more domain-specific SciBERT and PubMedBERT models, suggesting that this specialization might be hindering in this context. This difference could also be explained by the size of the models’ training datasets: BERT was trained on 3.3 billion words <span class="citation" data-cites="devlin_etal19">(<a href="#ref-devlin_etal19" role="doc-biblioref">Devlin et al., 2019</a>)</span>, whereas SciBERT and PubMedBERT were trained on 3.17 billion tokens <span class="citation" data-cites="beltagy_etal19">(words or word fragments; <a href="#ref-beltagy_etal19" role="doc-biblioref">Beltagy et al., 2019</a>)</span> and 3.1 billion words <span class="citation" data-cites="gu_etal22">(<a href="#ref-gu_etal22" role="doc-biblioref">Gu et al., 2022</a>)</span>, respectively. BERT may therefore have achieved slightly better results simply because its broader and larger training data allowed it to represent sentence structure more effectively. Of course, the difference could also stem from numerous other factors in the models’ training configurations. Future research should examine whether this performance gap persists across related tasks.</p>
<p>Similarly, with respect to this study’s training data (articles from Psychological Science published between 2013 and 2024), the findings should not be overgeneralized. While the trained BERT classifiers will likely detect misinterpretations in articles from other journals and time periods as well, the training dataset would nonetheless benefit from being expanded and diversified to cover a broader range of psychological research.</p>
<p>While the standard BERT model performed well overall, it still misclassified edge cases, particularly statements containing both correct and incorrect elements. For example, ‘the difference was not significant, suggesting there is no effect’ combines a factual result with a problematic inference. As can be seen in <a href="#tbl-false-classification" class="quarto-xref" aria-expanded="false">Table&nbsp;2</a>, all three models often classified such statements wholly as correct. This might be due to the regularity of word choice across classes: correct statements almost always contained the word ‘significant(ly)’, whereas incorrect statements varied more in their phrasing (e.g., ‘no effect/difference’, ‘groups were the same’, ‘X did not moderate’). Consequently, once a statement includes significant, the model is heavily nudged toward predicting it as correct, even if it also contains problematic elements. Similarly, if correct statements did not use the word ‘significant’ explicitly, models sometimes misclassified these as incorrect. These issues might be mitigated through more advanced control of the weights the models assign to specific characteristics of a statement. Nevertheless, this still illustrates the difficulty of reducing nuanced writing to a binary label. Splitting statements into parts or using non-binary classification approaches might therefore be useful.</p>
<p>A more practical challenge involves managing models’ tradeoff between false positive and false negative predictions. The current models aim to balance both for optimal macro performance (as seen in the results, this was not perfectly possible). However, in practice, different use cases may prioritize one over the other. For example, an individual researcher using the system to improve their writing may prefer fewer false negatives (i.e., catching as many problematic statements as possible), even at the cost of some false positives. Conversely, a meta-scientist analyzing prevalence trends of this misinterpretation may prioritize precision to avoid overestimating misinterpretations. One way to address this is by allowing users to adjust the model’s decision threshold for predicting one label or the other. A future Papercheck module based on this work could incorporate such functionality to fit users’ specific goals.</p>
<p>Lastly, the correction stage revealed both opportunities and challenges. LLMs were able to propose helpful revisions, but, as shown in <a href="#tbl-LLM-corrections-1" class="quarto-xref" aria-expanded="false">Table&nbsp;3</a>, they also turned already-correct statements incorrect or produced overly generic revisions. Providing them with more context (e.g., the preceding and following sentences or the full paragraph), alongside continued prompt engineering, might improve their ability to generate accurate and nuanced corrections.</p>
<p>However, there is also the flip side to the aforementioned human factors perspective: should authors rely on AI-generated corrections at all? Unlike grammar mistakes that word processors automatically fix for us, misinterpretations of statistical results often stem from deeper conceptual misunderstandings. Automated corrections might inadvertently encourage passivity, shifting responsibility away from researchers’ own critical engagement. In this sense, corrections should, if included at all, be seen as optional guidance, not authoritative replacements for careful reasoning. Alternatively, LLMs could be used to generate explanations of why a given statement is incorrect.</p>
</section>
<section id="implications-and-future-directions" class="level2">
<h2 data-anchor-id="implications-and-future-directions">4.3 Implications and Future Directions</h2>
<p>The pipeline described in this study will be integrated into a new Papercheck module for identifying potential misinterpretations of nonsignificant results. Some clear aspects to improve have been detected in this study: Firstly, the current RegEx searches of Papercheck’s ‘all_p_values’ module might not be optimized to detect all different ways in which a <em>p</em> values can be written. For example, the previously mentioned <span class="math inline">p_s</span> is often used to refer to the smallest <em>p</em> value in some collection of tests. This is an example of usually irrelevant RegEx’s that I will add to improve this automatic detection of candidate statements. Additionally, the dataset used to train the BERT models will also be expanded and re-checked by independent coders to ensure that the aspects the models do pick up are generalizable. Lastly, errors from the LLM-revised corrections will be closely analyzed to inform further prompt engineering and ultimately minimize mistakes.</p>
<p>A broader implication concerns how nonsignificant results should be reported in general. These interpretations are not free-form expressions that authors can adapt to suit their way of writing but rather formalized claims where certain phrasings are demonstrably misleading. Automated systems can support a shift toward clearer and more standardized reporting practices, but ultimately, researchers must recognize their own responsibility in this regard.</p>
<p>This issue is closely connected to the larger question of why such misinterpretations remain highly prevalent despite decades of critique, a phenomenon likely driven by multiple factors. Educational gaps leave many students and researchers uncertain about how to interpret <em>p</em> values correctly, as instructors may share the same misconceptions <span class="citation" data-cites="haller_krauss02">(<a href="#ref-haller_krauss02" role="doc-biblioref">Haller &amp; Krauss, 2002</a>)</span> or textbooks may themselves misrepresent key statistical concepts <span class="citation" data-cites="cassidy_etal19">(<a href="#ref-cassidy_etal19" role="doc-biblioref">Cassidy et al., 2019</a>)</span>. Similarly, researchers might have different philosophies of science and might disagree about how to interpret key statistics like the <em>p</em> value <span class="citation" data-cites="lakens21">(<a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. Finally, the widespread prevalence of misinterpretations itself might create a self-reinforcing cycle, with researchers adopting the language they encounter in published articles and thereby perpetuating the problem. Automated feedback systems cannot resolve these deeper causes, but they may, for now, assist individual authors by highlighting such mistakes in their own work.</p>
<p>Additionally, the pipeline’s stepwise structure makes it easy to adapt to other classification or correction tasks than the one presented in this study. For instance, users could train custom classifiers to detect different issues in reporting practices <span class="citation" data-cites="vanabkoude25">(see <a href="#ref-vanabkoude25" role="doc-biblioref">van Abkoude, 2025</a> for an application to problematic causal language)</span>. In practice, this would involve specifying RegEx patterns that capture the target aspects, training classifiers to label them as correct or incorrect, and, if desired, creating a prompt to generate corrections. Depending on the issue at hand, such classifiers could also be trained on existing hand-labeled datasets from meta-scientific studies where researchers coded specific practices or mistakes <span class="citation" data-cites="aczel_etal18">(e.g., <a href="#ref-aczel_etal18" role="doc-biblioref">Aczel et al., 2018</a>)</span>.</p>
<p>Finally, the most important next step for this project is to conduct qualitative user studies to explore how authors would prefer a tool like this to be designed and implemented. A central question will again concern the role of the optional correction feature: do authors find value in receiving suggested corrections, or is simple flagging sufficient? These studies could also reveal where customization is most useful (e.g., varying levels of strictness, setting a personal alpha level instead of the conventional 5%, etc.). In addition, experimental evaluations would help assess whether the tool reduces the prevalence of misinterpretations and increases authors’ awareness of them.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>5 Conclusion</h1>
<p>This study demonstrates that a hybrid rule-based and NLP-driven pipeline can effectively detect, classify, and correct the common statistical misinterpretation that nonsignificant results are evidence for the absence of an effect. Each of these steps performed well independently. The next step is to evaluate the pipeline as a fully automated system in real-world use cases and conduct qualitative user studies to inform the tool’s implementation. With further refinement, automated manuscript checks like the one presented in this article could substantially improve the accuracy of scientific reporting, while also providing a valuable resource for large-scale meta-scientific analyses.</p>
</section>
<section id="achknowledgement" class="level1">
<h1>Achknowledgement</h1>
<p>I want to thank Dr.&nbsp;Daniël Lakens for his constant support throughout this thesis and for a wonderful research stay that allowed me to work on it in person. I thank Solveig Steland for her unwavering support, for encouraging me when I felt discouraged, and for very insightful discussions on whether and how we (should and) should not use AI. I also thank Prof.&nbsp;Dr.&nbsp;Maike Luhmann for allowing me to pursue a meta-scientific project that is so close to my heart, even though it falls somewhat outside her area of expertise. Finally, I thank Christian Sodano for helpful discussions about machine learning and BERT models, which helped to ensure that my model training did not turn into ‘algorithmic <em>p</em>-hacking’.</p>
</section>
<section id="references" class="level1">
<h1>References</h1>
<!-- References will auto-populate in the refs div below -->
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-aczel_etal18" class="csl-entry" role="listitem">
Aczel, B., Palfi, B., Szollosi, A., Kovacs, M., Szaszi, B., Szecsi, P., Zrubka, M., Gronau, Q. F., Van Den Bergh, D., &amp; Wagenmakers, E.-J. (2018). Quantifying <span>Support</span> for the <span>Null Hypothesis</span> in <span>Psychology</span>: <span>An Empirical Investigation</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(3), 357–366. <a href="https://doi.org/10.1177/2515245918773742">https://doi.org/10.1177/2515245918773742</a>
</div>
<div id="ref-altman_bland95" class="csl-entry" role="listitem">
Altman, D. G., &amp; Bland, J. M. (1995). Statistics notes: <span>Absence</span> of evidence is not evidence of absence. <em>BMJ</em>, <em>311</em>(7003), 485–485. <a href="https://doi.org/10.1136/bmj.311.7003.485">https://doi.org/10.1136/bmj.311.7003.485</a>
</div>
<div id="ref-amrhein_etal19" class="csl-entry" role="listitem">
Amrhein, V., Greenland, S., &amp; McShane, B. (2019). Scientists rise up against statistical significance. <em>Nature</em>, <em>567</em>(7748), 305–307. <a href="https://doi.org/10.1038/d41586-019-00857-9">https://doi.org/10.1038/d41586-019-00857-9</a>
</div>
<div id="ref-R-papaja" class="csl-entry" role="listitem">
Aust, F., &amp; Barth, M. (2024). <em><span class="nocase">papaja</span>: <span>Prepare</span> reproducible <span>APA</span> journal articles with <span>R Markdown</span></em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.papaja">https://doi.org/10.32614/CRAN.package.papaja</a>
</div>
<div id="ref-badenes-ribera_etal16" class="csl-entry" role="listitem">
Badenes-Ribera, L., Frias-Navarro, D., Iotti, B., Bonilla-Campos, A., &amp; Longobardi, C. (2016). Misconceptions of the p-value among <span>Chilean</span> and <span>Italian Academic Psychologists</span>. <em>Frontiers in Psychology</em>, <em>7</em>. <a href="https://doi.org/10.3389/fpsyg.2016.01247">https://doi.org/10.3389/fpsyg.2016.01247</a>
</div>
<div id="ref-beltagy_etal19" class="csl-entry" role="listitem">
Beltagy, I., Lo, K., &amp; Cohan, A. (2019). <em><span>SciBERT</span>: <span>A Pretrained Language Model</span> for <span>Scientific Text</span></em>. <a href="https://doi.org/10.48550/ARXIV.1903.10676">https://doi.org/10.48550/ARXIV.1903.10676</a>
</div>
<div id="ref-cassidy_etal19" class="csl-entry" role="listitem">
Cassidy, S. A., Dimova, R., Giguère, B., Spence, J. R., &amp; Stanley, D. J. (2019). Failing <span>Grade</span>: 89% of <span class="nocase">Introduction-to-Psychology Textbooks That Define</span> or <span>Explain Statistical Significance Do So Incorrectly</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>2</em>(3), 233–239. <a href="https://doi.org/10.1177/2515245919858072">https://doi.org/10.1177/2515245919858072</a>
</div>
<div id="ref-cummin_hussey25" class="csl-entry" role="listitem">
Cummin, J., &amp; Hussey, I. (2025). <em><span>RegCheck</span>. <span>Compare</span> preregistrations with papers. <span>Instantly</span>.</em> Available at https://regcheck.app/.
</div>
<div id="ref-R-papercheck" class="csl-entry" role="listitem">
DeBruine, L., &amp; Lakens, D. (2025). <em>Papercheck: <span>Check</span> scientific papers for best practices</em> [Manual].
</div>
<div id="ref-devlin_etal19" class="csl-entry" role="listitem">
Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). <span>BERT</span>: <span class="nocase">Pre-training</span> of <span>Deep Bidirectional Transformers</span> for <span>Language Understanding</span>. <em>Proceedings of the 2019 <span>Conference</span> of the <span>North</span></em>, 4171–4186. <a href="https://doi.org/10.18653/v1/N19-1423">https://doi.org/10.18653/v1/N19-1423</a>
</div>
<div id="ref-dienes14" class="csl-entry" role="listitem">
Dienes, Z. (2014). Using <span>Bayes</span> to get the most out of non-significant results. <em>Frontiers in Psychology</em>, <em>5</em>. <a href="https://doi.org/10.3389/fpsyg.2014.00781">https://doi.org/10.3389/fpsyg.2014.00781</a>
</div>
<div id="ref-edwards_etal63" class="csl-entry" role="listitem">
Edwards, W., Lindman, H., &amp; Savage, L. J. (1963). Bayesian statistical inference for psychological research. <em>Psychological Review</em>, <em>70</em>(3), 193–242. <a href="https://doi.org/10.1037/h0044139">https://doi.org/10.1037/h0044139</a>
</div>
<div id="ref-gelman_stern06" class="csl-entry" role="listitem">
Gelman, A., &amp; Stern, H. (2006). The <span>Difference Between</span> <span>“<span>Significant</span>”</span> and <span>“<span>Not Significant</span>”</span> is not <span>Itself Statistically Significant</span>. <em>The American Statistician</em>, <em>60</em>(4), 328–331. <a href="https://doi.org/10.1198/000313006X152649">https://doi.org/10.1198/000313006X152649</a>
</div>
<div id="ref-R-flextable" class="csl-entry" role="listitem">
Gohel, D., &amp; Skintzos, P. (2025). <em>Flextable: <span>Functions</span> for tabular reporting</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.flextable">https://doi.org/10.32614/CRAN.package.flextable</a>
</div>
<div id="ref-goodman08" class="csl-entry" role="listitem">
Goodman, S. (2008). A <span>Dirty Dozen</span>: <span>Twelve P-Value Misconceptions</span>. <em>Seminars in Hematology</em>, <em>45</em>(3), 135–140. <a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">https://doi.org/10.1053/j.seminhematol.2008.04.003</a>
</div>
<div id="ref-greenland19" class="csl-entry" role="listitem">
Greenland, S. (2019). Valid <span><em>P</em></span> -<span>Values Behave Exactly</span> as <span>They Should</span>: <span>Some Misleading Criticisms</span> of <span><em>P</em></span> -<span>Values</span> and <span>Their Resolution With</span> <span><em>S</em></span> -<span>Values</span>. <em>The American Statistician</em>, <em>73</em>(sup1), 106–114. <a href="https://doi.org/10.1080/00031305.2018.1529625">https://doi.org/10.1080/00031305.2018.1529625</a>
</div>
<div id="ref-greenland_etal16" class="csl-entry" role="listitem">
Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., &amp; Altman, D. G. (2016). Statistical tests, <span>P</span> values, confidence intervals, and power: A guide to misinterpretations. <em>European Journal of Epidemiology</em>, <em>31</em>(4), 337–350. <a href="https://doi.org/10.1007/s10654-016-0149-3">https://doi.org/10.1007/s10654-016-0149-3</a>
</div>
<div id="ref-gu_etal22" class="csl-entry" role="listitem">
Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., &amp; Poon, H. (2022). Domain-<span>Specific Language Model Pretraining</span> for <span>Biomedical Natural Language Processing</span>. <em>ACM Transactions on Computing for Healthcare</em>, <em>3</em>(1), 1–23. <a href="https://doi.org/10.1145/3458754">https://doi.org/10.1145/3458754</a>
</div>
<div id="ref-haller_krauss02" class="csl-entry" role="listitem">
Haller, H., &amp; Krauss, S. (2002). <em>Misinterpretations of <span>Significance</span>: <span>A</span> problem students share with their teachers?</em> <a href="https://doi.org/10.5283/EPUB.34338">https://doi.org/10.5283/EPUB.34338</a>
</div>
<div id="ref-heathers_etal18" class="csl-entry" role="listitem">
Heathers, J. A., Anaya, J., Van Der Zee, T., &amp; Brown, N. J. (2018). <em>Recovering data from summary statistics: <span>Sample Parameter Reconstruction</span> via <span>Iterative TEchniques</span> (<span>SPRITE</span>)</em>. <a href="https://doi.org/10.7287/peerj.preprints.26968v1">https://doi.org/10.7287/peerj.preprints.26968v1</a>
</div>
<div id="ref-hoekstra_etal06" class="csl-entry" role="listitem">
Hoekstra, R., Finch, S., Kiers, H. A. L., &amp; Johnson, A. (2006). Probability as certainty: <span>Dichotomous</span> thinking and the misuse of p values. <em>Psychonomic Bulletin &amp; Review</em>, <em>13</em>(6), 1033–1037. <a href="https://doi.org/10.3758/BF03213921">https://doi.org/10.3758/BF03213921</a>
</div>
<div id="ref-isager_fitzgerald25" class="csl-entry" role="listitem">
Isager, P. M., &amp; Fitzgerald, J. (2025). <em>Three-<span>Sided Testing</span> to <span>Establish Practical Significance</span>: <span>A Tutorial</span></em>. <a href="https://doi.org/10.31234/osf.io/8y925">https://doi.org/10.31234/osf.io/8y925</a>
</div>
<div id="ref-R-magick" class="csl-entry" role="listitem">
Jeroen, O. (2025). <em>Magick: <span>Advanced Graphics</span> and <span>Image-Processing</span> in <span>R</span></em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.magick">https://doi.org/10.32614/CRAN.package.magick</a>
</div>
<div id="ref-lakens21" class="csl-entry" role="listitem">
Lakens, D. (2021). The <span>Practical Alternative</span> to the <span><em>p</em></span> <span>Value Is</span> the <span>Correctly Used</span> <span><em>p</em></span> <span>Value</span>. <em>Perspectives on Psychological Science</em>, <em>16</em>(3), 639–648. <a href="https://doi.org/10.1177/1745691620958012">https://doi.org/10.1177/1745691620958012</a>
</div>
<div id="ref-lakens_etal18" class="csl-entry" role="listitem">
Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S.-C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., … Zwaan, R. A. (2018). Justify your alpha. <em>Nature Human Behaviour</em>, <em>2</em>(3), 168–171. <a href="https://doi.org/10.1038/s41562-018-0311-x">https://doi.org/10.1038/s41562-018-0311-x</a>
</div>
<div id="ref-mcshane_etal19" class="csl-entry" role="listitem">
McShane, B. B., Gal, D., Gelman, A., Robert, C., &amp; Tackett, J. L. (2019). Abandon <span>Statistical Significance</span>. <em>The American Statistician</em>, <em>73</em>(sup1), 235–245. <a href="https://doi.org/10.1080/00031305.2018.1527253">https://doi.org/10.1080/00031305.2018.1527253</a>
</div>
<div id="ref-more25" class="csl-entry" role="listitem">
More, R. (2025). <em>Fine-<span>Tuning BERT</span> for <span>Text Classification Using Hugging Face Transformers</span></em>.
</div>
<div id="ref-murphy_etal25" class="csl-entry" role="listitem">
Murphy, S. L., Merz, R., Reimann, L.-E., &amp; Fernández, A. (2025). Nonsignificance misinterpreted as an effect’s absence in psychology: <span>Prevalence</span> and temporal analyses. <em>Royal Society Open Science</em>, <em>12</em>(3), 242167. <a href="https://doi.org/10.1098/rsos.242167">https://doi.org/10.1098/rsos.242167</a>
</div>
<div id="ref-nuijten_epskamp24" class="csl-entry" role="listitem">
Nuijten, M. B., &amp; Epskamp, S. (2024). <em>Statcheck: <span>Extract</span> statistics from articles and recompute p-<span>Values</span>. <span>R</span> package version 1.5.0.</em> Web implementation at https://statcheck.io.
</div>
<div id="ref-python" class="csl-entry" role="listitem">
Python Software Foundation. (2025). <em>Python: A dynamic, open source programming language</em> [Manual]. Python Software Foundation.
</div>
<div id="ref-R-showtext" class="csl-entry" role="listitem">
Qiu, Y., &amp; for details., authors/contributors. of the included software. S. file A. (2024). <em>Showtext: <span>Using</span> fonts more easily in <span>R</span> graphs</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.showtext">https://doi.org/10.32614/CRAN.package.showtext</a>
</div>
<div id="ref-schervish96" class="csl-entry" role="listitem">
Schervish, M. J. (1996). <span><em>P</em></span> <span>Values</span>: <span>What They</span> are and <span>What They</span> are <span>Not</span>. <em>The American Statistician</em>, <em>50</em>(3), 203–206. <a href="https://doi.org/10.1080/00031305.1996.10474380">https://doi.org/10.1080/00031305.1996.10474380</a>
</div>
<div id="ref-stillman19" class="csl-entry" role="listitem">
Stillman, D. (2019). <em>Retracted item notifications with <span>Retraction Watch</span> integration</em>.
</div>
<div id="ref-talebi24" class="csl-entry" role="listitem">
Talebi, S. (2024). <em>Fine-<span>Tuning BERT</span> for <span>Text Classification</span></em>.
</div>
<div id="ref-rcoreteam25" class="csl-entry" role="listitem">
Team, R. C. (2025). <em>R: <span>A Language</span> and <span>Environment</span> for <span>Statistical Computing</span></em> [Manual]. R Foundation for Statistical Computing.
</div>
<div id="ref-vanabkoude25" class="csl-entry" role="listitem">
van Abkoude, T. (2025). <em>Causal <span>Confusion</span>: <span>How LLMs Can Improve Causal Language</span> in <span>Research Communication</span></em> [Master's {{Thesis}}].
</div>
<div id="ref-wagenmakers07" class="csl-entry" role="listitem">
Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems of <span><em>p</em></span> values. <em>Psychonomic Bulletin &amp; Review</em>, <em>14</em>(5), 779–804. <a href="https://doi.org/10.3758/BF03194105">https://doi.org/10.3758/BF03194105</a>
</div>
<div id="ref-R-tidyverse" class="csl-entry" role="listitem">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the <span class="nocase">tidyverse</span>. <em>Journal of Open Source Software</em>, <em>4</em>(43), 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>
</div>
<div id="ref-R-readxl" class="csl-entry" role="listitem">
Wickham, H., &amp; Bryan, J. (2025). <em>Readxl: <span>Read</span> excel files</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.readxl">https://doi.org/10.32614/CRAN.package.readxl</a>
</div>
<div id="ref-R-psych" class="csl-entry" role="listitem">
William Revelle. (2025). <em>Psych: <span>Procedures</span> for psychological, psychometric, and personality research</em> [Manual]. Northwestern University.
</div>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In the final Papercheck module, users will be able to set the alpha level they used themselves, thus allowing other levels than the conventional 5%.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>I could not find one statement that was detected automatically in the article’s PDF. My current theory is that this was an artifact from when the PDF was compiled and might be from a different article even, highlighting how impractical the PDF format is in times of increasing automation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>