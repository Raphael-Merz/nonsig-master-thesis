<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Raphael Merz">
<meta name="keywords" content="p value, misinterpretation, automation, automated checks, RegEx, LLMs, BERT">
<meta name="description" content="HYBRID NLP FOR CORRECTING p VALUE MISINTERPRETATIONS">

<title>From Detection to Correction: A Hybrid NLP Approach to Misinterpretations of Nonsignificant p Values</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="thesis_files/libs/clipboard/clipboard.min.js"></script>
<script src="thesis_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="thesis_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="thesis_files/libs/quarto-html/popper.min.js"></script>
<script src="thesis_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="thesis_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="thesis_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="thesis_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="thesis_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="thesis_files/libs/bootstrap/bootstrap-accd75c2bd871f03c4c02dcc9260e8c4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="thesis_files/libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">

<script src="thesis_files/libs/tabwid-1.1.3/tabwid.js"></script>


  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="_extensions/wjschne/apaquarto/apa.css">
</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">1 Introduction</a>
  <ul class="collapse">
  <li><a href="#misinterpretations-and-criticism-of-p-values" id="toc-misinterpretations-and-criticism-of-p-values" class="nav-link" data-scroll-target="#misinterpretations-and-criticism-of-p-values">1.1 Misinterpretations and Criticism of <em>P</em> Values</a></li>
  <li><a href="#possible-solutions" id="toc-possible-solutions" class="nav-link" data-scroll-target="#possible-solutions">1.2 Possible Solutions</a></li>
  </ul></li>
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">2 Methods</a>
  <ul class="collapse">
  <li><a href="#statement-detection-classification-and-correction" id="toc-statement-detection-classification-and-correction" class="nav-link" data-scroll-target="#statement-detection-classification-and-correction">2.1 Statement Detection, Classification and Correction</a></li>
  <li><a href="#validation-process-and-performance-metrics" id="toc-validation-process-and-performance-metrics" class="nav-link" data-scroll-target="#validation-process-and-performance-metrics">2.2 Validation Process and Performance Metrics</a></li>
  <li><a href="#software" id="toc-software" class="nav-link" data-scroll-target="#software">2.3 Software</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">3 Results</a>
  <ul class="collapse">
  <li><a href="#detection-accuracy" id="toc-detection-accuracy" class="nav-link" data-scroll-target="#detection-accuracy">3.1 Detection Accuracy</a></li>
  <li><a href="#classification-performance" id="toc-classification-performance" class="nav-link" data-scroll-target="#classification-performance">3.2 Classification Performance</a></li>
  <li><a href="#correction-evaluation" id="toc-correction-evaluation" class="nav-link" data-scroll-target="#correction-evaluation">3.3 Correction Evaluation</a></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">4 Discussion</a>
  <ul class="collapse">
  <li><a href="#summary-of-key-results" id="toc-summary-of-key-results" class="nav-link" data-scroll-target="#summary-of-key-results">4.1 Summary of Key Results</a></li>
  <li><a href="#limitations-and-challenges" id="toc-limitations-and-challenges" class="nav-link" data-scroll-target="#limitations-and-challenges">4.2 Limitations and Challenges</a></li>
  <li><a href="#practical-use-and-future-directions" id="toc-practical-use-and-future-directions" class="nav-link" data-scroll-target="#practical-use-and-future-directions">4.3 Practical Use and Future Directions</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">5 Conclusion</a></li>
  <li><a href="#achknowledgement" id="toc-achknowledgement" class="nav-link" data-scroll-target="#achknowledgement">Achknowledgement</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="thesis.pdf"><i class="bi bi-file-pdf"></i>PDF (apaquarto)</a></li><li><a href="thesis.pdf"><i class="bi bi-file-pdf"></i>Typst (apaquarto)</a></li><li><a href="thesis.docx"><i class="bi bi-file-word"></i>MS Word (apaquarto)</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">




<br>

<br>

<section id="title" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">From Detection to Correction: A Hybrid NLP Approach to Misinterpretations of Nonsignificant <em>p</em> Values</h1>
<div class="Author">
<br>

<p>Raphael Merz</p>
<p>Department of Psychology, Ruhr University Bochum</p>
</div>
<br>

<br>

</section>
<section id="author-note" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Author Note</h1>
<p>Raphael Merz <img src="_extensions/wjschne/apaquarto/ORCID-iD_icon-vector.svg" id="orchid" class="img-fluid" style="width:4.23mm" alt="Orcid ID Logo: A green circle with white letters ID"> <a href="https://orcid.org/0000-0002-9474-3379">https://orcid.org/0000-0002-9474-3379</a></p>
<p>Correspondence concerning this article should be addressed to Raphael Merz, Department of Psychology, Ruhr University Bochum, Bochum, Germany, Email: raphael.merz@rub.de</p>
</section>
<section id="abstract" class="level1 unnumbered unlisted AuthorNote">
<h1 class="unnumbered unlisted AuthorNote">Abstract</h1>
<div class="AbstractFirstParagraph">
<p>Misinterpretations of <em>p</em> values remain a highly prevalent issue in scientific reporting, despite decades of educational efforts and reform initiatives. Among the most frequent and consequential misinterpretations is the conclusion that a statistically nonsignificant result (e.g., <em>p</em> &gt; .05) implies the absence of an effect – a claim not supported by the logic of null hypothesis significance testing (NHST). This project draws on a human factors perspective, arguing that automation can offer practical, scalable solutions to persistent statistical errors – comparable to how word processors flag potential spelling and grammar mistakes. This master’s thesis project proposes the development of an automated tool to detect, classify, and correct such misinterpretations using a combination of rule-based searches, large language models (LLMs), and machine learning classifiers. Building on the existing papercheck framework – an R package created to make automated checks of academic manuscripts easier and more systematic – the project aims to identify statements interpreting nonsignificant results, determine whether these interpretations are correct, and suggest improved phrasing if they are not. Initial detection will rely on rule-based text searches to locate candidate sentences, which will then be filtered and contextualized using LLMs. Classification of interpretations as correct or incorrect will be achieved through transformer-based classifiers (BERT, SciBERT, PubMedBERT), which will be evaluated against human-coded ground truth data. In its final form, the tool will serve as a writing assistant, a research instrument for large-scale corpus analysis, and an extension of papercheck. Ultimately, the goal is to reduce misinterpretations of nonsignificant findings and contribute to more accurate and informative scientific reporting.</p>
</div>
<p><em>Keywords</em>: p value, misinterpretation, automation, automated checks, RegEx, LLMs, BERT</p>
</section>
<section id="firstheader" class="level1 title unnumbered unlisted">
<h1 class="title unnumbered unlisted">From Detection to Correction: A Hybrid NLP Approach to Misinterpretations of Nonsignificant <em>p</em> Values</h1>
</section>
<section id="introduction" class="level1">
<h1>1 Introduction</h1>
<p>Over the past decades, numerous articles have addressed common misinterpretations of <em>p</em> values in the context of standard null hypothesis significance testing (NHST) <span class="citation" data-cites="goodman08 greenland_etal16 schervish96">(<a href="#ref-goodman08" role="doc-biblioref">Goodman, 2008</a>; <a href="#ref-greenland_etal16" role="doc-biblioref">Greenland et al., 2016</a>; <a href="#ref-schervish96" role="doc-biblioref">Schervish, 1996</a>)</span>. Some go further, questioning the use of frequentist methods altogether <span class="citation" data-cites="edwards_etal63 wagenmakers07">(<a href="#ref-edwards_etal63" role="doc-biblioref">Edwards et al., 1963</a>; <a href="#ref-wagenmakers07" role="doc-biblioref">Wagenmakers, 2007</a>)</span>, while others propose refinements within the frequentist framework that aim to improve the informativeness of statistical inference <span class="citation" data-cites="isager_fitzgerald25 lakens_etal18">(<a href="#ref-isager_fitzgerald25" role="doc-biblioref">Isager &amp; Fitzgerald, 2025</a>; <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span>. If you are a researcher writing a paper and want to interpret your results correctly, the solution seems simple: read these educational resources and revise your manuscript accordingly. Easy, right? Still, empirical studies consistently show that these misinterpretations remain widespread <span class="citation" data-cites="hoekstra_etal06 murphy_etal25">(<a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>; <a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. Why is that? What makes interpreting <em>p</em> values so persistently difficult? Which practical solutions or promising approaches might help? And are some of the proposed ‘misinterpretation checklists’ perhaps less informative than their authors would hope?</p>
<p>In this article, I show how rule-based approaches, combined with natural language processing (NLP) can be used to automatically detect, classify, and correct these misinterpretation. I show this for the misinterpretation of statistically nonsignificant results as the absence of an effect because it is the most extensively researched misinterpretation of <em>p</em> values <span class="citation" data-cites="lakens21">(<a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>, and I have experience in classifying them from a previous project <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. That said, the general framework I propose can be easily adapted to address other misinterpretations beyond <em>p</em> values.</p>
<section id="misinterpretations-and-criticism-of-p-values" class="level2">
<h2 data-anchor-id="misinterpretations-and-criticism-of-p-values">1.1 Misinterpretations and Criticism of <em>P</em> Values</h2>
<p>The criticism of <em>p</em> values has become a prominent and recurring theme in discussions around scientific reform. From claims that they encourage dichotomous thinking <span class="citation" data-cites="hoekstra_etal06 amrhein_etal19">(<a href="#ref-amrhein_etal19" role="doc-biblioref">Amrhein et al., 2019</a>; <a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>)</span> to arguments that they offer little informational value <span class="citation" data-cites="wagenmakers07">(<a href="#ref-wagenmakers07" role="doc-biblioref">Wagenmakers, 2007</a>)</span>, <em>p</em> values – and the broader framework of NHST – have been blamed for many of science’s replication problems <span class="citation" data-cites="mcshane_etal19">(<a href="#ref-mcshane_etal19" role="doc-biblioref">McShane et al., 2019</a>)</span>. On the other hand, many have also argued that NHST per se is not to blame for these problems, but rather how researchers (mis)use and (mis)interpret this tool <span class="citation" data-cites="lakens21">(<a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. As a result, many researchers present whole collections of, in their view, common <em>p</em> value misinterpretations <span class="citation" data-cites="goodman08 greenland_etal16">(see, e.g., <a href="#ref-goodman08" role="doc-biblioref">Goodman, 2008</a>; <a href="#ref-greenland_etal16" role="doc-biblioref">Greenland et al., 2016</a>)</span>. Reviewing these, I see four key misconceptions about <em>p</em> values that seem to be at play:</p>
<ul>
<li><em>p</em> values as hypothesis probabilities</li>
<li><em>p</em> values as measures of practical significance</li>
<li><em>p</em> values as measures of replicability or error rates</li>
<li>Technical misunderstandings about <em>p</em> values</li>
</ul>
<p>[NOTE FROM RAPHAEL: I left this part in for now, because it was part of the original proposal and I didn’t fully rewrite the Intro yet: However, I think that this doesn’t really work for the thesis/this article anymore. I feel like this would be a Review paper on its own and then automatically fixing some of these misconceptions would be, again, a new paper. Given the tight word limit (5000 words), I think I will just briefly put the “p &gt; .05 = no effect” misinterpretation in the context of p value criticism in general, but then not mention this “I came up with these four categories” bit. But let me know what you think!]</p>
<p>In my master thesis, I will zoom in on one specific misinterpretation: concluding <em>no effect</em> based on a statistically nonsignificant finding. Many studies have previously shown that this misinterpretation is and remains highly prevalent across time and sub-domains of psychology <span class="citation" data-cites="aczel_etal18 hoekstra_etal06 murphy_etal25">(e.g., <a href="#ref-aczel_etal18" role="doc-biblioref">Aczel et al., 2018</a>; <a href="#ref-hoekstra_etal06" role="doc-biblioref">Hoekstra et al., 2006</a>; <a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. In fact, in a recently published article investigating articles published in 2009, 2015, and 2021 across ten different psychology journals, we estimated the prevalence of this misinterpretation in articles’ discussion sections to lie between 76.17% and 84.90% <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. This study highlights that the situation seems not to have greatly improved despite many researchers exploring new analysis techniques <span class="citation" data-cites="lakens_etal18">(e.g., <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span> and continuous calls to reflect on interpretations of nonsignificant results <span class="citation" data-cites="mcshane_etal19">(e.g., <a href="#ref-mcshane_etal19" role="doc-biblioref">McShane et al., 2019</a>)</span>.</p>
</section>
<section id="possible-solutions" class="level2">
<h2 data-anchor-id="possible-solutions">1.2 Possible Solutions</h2>
<p>One frequently suggested solution is to improve researchers’ statistical literacy through enhanced education, such as better statistics teaching at the undergraduate and graduate levels <span class="citation" data-cites="lakens21">(e.g., <a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>. However, as noted earlier, the prevalence of the misinterpretation I focus on does not seem to have substantially decreased, suggesting that calls for better education alone have not resolved the problem <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. Relatedly, researchers have also advocated for the use of interval hypotheses tests, like equivalence testing or minimum-effect tests <span class="citation" data-cites="isager_fitzgerald25">(or the combination: three-sided testing; <a href="#ref-isager_fitzgerald25" role="doc-biblioref">Isager &amp; Fitzgerald, 2025</a>)</span>. These methods allow researchers to test whether an effect is practically relevant and larger than a predefined smallest effect size of interest <span class="citation" data-cites="lakens_etal18">(SESOI; <a href="#ref-lakens_etal18" role="doc-biblioref">Lakens et al., 2018</a>)</span>. In many contexts, such approaches might be more closely aligned with the substantive questions researchers aim to answer, namely whether an effect is meaningful in practice.</p>
<p>These strategies also align with the argument made by <span class="citation" data-cites="lakens21">Lakens (<a href="#ref-lakens21" role="doc-biblioref">2021</a>)</span> that <em>p</em> value misinterpretations represent a human factors problem, requiring practical and easy-to-implement solutions. In other context, we encounter systems like this frequently, be it cars’ automatic braking systems, word processors that flag spelling and grammar mistakes, or email clients that filter out malware and phishing attempts. Analogously, and recognizing that new analytic approaches may not be adopted overnight, automated checks for statistical misinterpretations offer a highly promising route. This perspective emphasizes that many statistical errors arise not from bad intentions or ignorance, but from cognitive limitations and suboptimal workflows.</p>
<p>In the context of research, similar automated solutions are already gaining traction. For instance, the reference manager Zotero flags references to retracted papers <span class="citation" data-cites="stillman19">(<a href="#ref-stillman19" role="doc-biblioref">Stillman, 2019</a>)</span>. Statcheck <span class="citation" data-cites="nuijten_epskamp24">(<a href="#ref-nuijten_epskamp24" role="doc-biblioref">Nuijten &amp; Epskamp, 2024</a>)</span> automatically detects inconsistencies between reported test statistics and <em>p</em> values. Other tools, like GRIM, GRIMMER, and SPRITE, identify impossible values in reported summary statistics <span class="citation" data-cites="heathers_etal18">(<a href="#ref-heathers_etal18" role="doc-biblioref">Heathers et al., 2018</a>)</span>. And lastly, Regcheck <span class="citation" data-cites="cummin_hussey24">(<a href="#ref-cummin_hussey24" role="doc-biblioref"><strong>cummin_hussey24?</strong></a>)</span> verifies the consistency between manuscripts and their preregistration documents.</p>
<p>To make the process of checking manuscripts more systematic, <span class="citation" data-cites="R-papercheck">DeBruine and Lakens (<a href="#ref-R-papercheck" role="doc-biblioref">2025</a>)</span> developed papercheck, an R package, which allows users to run a battery of checks on scientific papers. These include statistical checks (e.g., identifying imprecisely reported <em>p</em> values) as well as general manuscript quality checks (e.g., verifying links to online repositories or consistency between in-text citations and reference lists). Papercheck can be used both for single articles (e.g., as writing assistance) and for batches of articles (e.g., for meta-scientific studies). Because this framework is actively maintained and continues to evolve, the approach presented in this study was designed to fit within the papercheck infrastructure.</p>
<p>In summary, there are many reasons why <em>p</em> values remain difficult to interpret correctly. Empirical evidence suggests that misinterpretations of nonsignificant results remain highly prevalent <span class="citation" data-cites="murphy_etal25">(<a href="#ref-murphy_etal25" role="doc-biblioref">Murphy et al., 2025</a>)</span>. This persistence highlights that improved education alone may not be sufficient. Drawing on a human factors perspective <span class="citation" data-cites="lakens21">(<a href="#ref-lakens21" role="doc-biblioref">Lakens, 2021</a>)</span>, practical solutions such as automated error-checking tools offer a promising avenue for addressing these challenges. In this project, I develop a pipeline to automatically detect, classify and optionally correct one such error: interpreting nonsignificant results as the absence of an effect. The pipeline builds on and is integrated into the existing papercheck framework <span class="citation" data-cites="R-papercheck">(<a href="#ref-R-papercheck" role="doc-biblioref">DeBruine &amp; Lakens, 2025</a>)</span>, a modular R package designed to support statistical and quality checks across scientific manuscripts. The next section outlines the methods I use to implement and evaluate this approach.</p>
</section>
</section>
<section id="methods" class="level1">
<h1>2 Methods</h1>
<section id="statement-detection-classification-and-correction" class="level2">
<h2 data-anchor-id="statement-detection-classification-and-correction">2.1 Statement Detection, Classification and Correction</h2>
<p>Before describing the data used in this study, it is important to understand the three steps of the proposed framework. Statements from scientific articles needed to be reliably detected, classified, and finally corrected. For each step, I applied specific methods that were best suited to achieve the respective goal.</p>
<p>To detect statements I searched used rule-based regular expressions (RegEx) and searched articles’s results sections for them. Effectively, RegEx searchers are more complex Ctrl+F searches, where a user can also include rules like optional characters (e.g., ‘significant(ly)’ would catch both <em>significant</em> and <em>significantly</em>) and more complex rules (e.g., ‘not.{0,20}significant’ allows up to 20 characters between <em>not</em> and <em>significant</em>). Papercheck <span class="citation" data-cites="R-papercheck">(<a href="#ref-R-papercheck" role="doc-biblioref">DeBruine &amp; Lakens, 2025</a>)</span> has a module that detects almost all <em>p</em> values (see Section 3.1 for examples of what it does not currently detect) based on RegEx searches and I filtered these to just the ones equal to or above .05. I then expanded the extracted nonsignificant <em>p</em> values to the full sentence with papercheck and added +/- one sentence as context in case of extraction errors (incomplete statements).<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>In the next step, these statements (labeled as correct or incorrect by me; see Section 2.2) were used to train three BERT-based models. BERT (Bidirectional Encoder Representations from Transformers) is a general-purpose language model pre-trained on the BookCorpus and English Wikipedia, making it suitable for a wide range of tasks – but not specifically optimized for scientific or technical language <span class="citation" data-cites="devlin_etal19">(<a href="#ref-devlin_etal19" role="doc-biblioref">Devlin et al., 2019</a>)</span>. Since its introduction, many researchers have developed domain-specific variants of BERT to enhance its performance on specialized tasks. To test whether such domain adaptation improves performance in this study’s classification task, I trained two models in addition to standard BERT: SciBERT was trained on a large corpus of scientific articles from Semantic Scholar, particularly in the biomedical and computer science domains <span class="citation" data-cites="beltagy_etal19">(<a href="#ref-beltagy_etal19" role="doc-biblioref">Beltagy et al., 2019</a>)</span>. PubMedBERT goes even further, having been trained exclusively on biomedical abstracts and full-text articles from the PubMed database <span class="citation" data-cites="gu_etal22">(<a href="#ref-gu_etal22" role="doc-biblioref">Gu et al., 2022</a>)</span>. These models were trained and evaluated on their ability to distinguish between correct and incorrect (as the absence of an effect) interpretations of nonsignificant results in scientific writing.</p>
<p>Lastly, statements that were classified by the best performing BERT model, would, in the application of this framework, be sent to an LLM to be corrected. However, for the purposes of this validation study, I sent statements which I coded as correct on incorrect to the LLM (more on this in Section 2.2). The full prompt is available in X was had X word. In short, the model was instructed to only change any misinterpretations of nonsignificant <em>p</em> values as the absence of an effect and keep the rest of the statement unchanged. To communicate with the LLM, I used papercheck <span class="citation" data-cites="R-papercheck">(<a href="#ref-R-papercheck" role="doc-biblioref">DeBruine &amp; Lakens, 2025</a>)</span>, which, in turn, uses the Groq API (available at <a href="https://groq.com/" class="uri">https://groq.com/</a>) to communicate with different LLMs. I used papercheck’s standard LLM, ‘llama-3.3-70b-versatile’ (as of 07/24/2025).</p>
</section>
<section id="validation-process-and-performance-metrics" class="level2">
<h2 data-anchor-id="validation-process-and-performance-metrics">2.2 Validation Process and Performance Metrics</h2>
<p>To assess how well each of these three automated approaches worked, I compared each one to human ground truth and calculated appropriate measures of reliability between automated and human results.</p>
<p>Firstly, to ensure that the statement detection process actually caught all statements with nonsignificant <em>p</em> values in articles’ results sections, I manually extracted these from 25 (10%) of the papercheck sample library’s 250 open access article from the journal Psychological Science. These articles were published between 2013 and 2024 (Median = 2021; IQA = [2018; 2022]). I then coded whether a statements I found were also extracted with the automated RegEx search.</p>
<p>For the training of the BERT models and to assess their final performance, I labeled all automatically extracted statements that were detected to be from an article’s results section from papercheck’s sample library. This resulted in 960 statements in total. Of these, 419 were classified as correct and 353 were classified as incorrect. The remaining 188 statements were classified as neither correct nor incorrect because they interpreted the nonsignificant effect as (marginally) significant (83), because the statements were not complete enough to check their correctness (20), because they interpreted model fit indices and not the <em>p</em> value (20), because they were ‘false flags’ of nonsignificant <em>p</em> values (19), nor really containing nonsignificant <em>p</em> values, or due to a combination of these or other reasons (46).</p>
<p>Lastly, I also also went through the 100 statements that were sent to an LLM to be corrected, to see if the ‘corrected’ statements were actually correct. Of these 100 statements, 80 had previously been labeled incorrect and 20 correct by me, to check how the LLM deals with false positives from the automated classification.</p>
<p>In addition to these validity checks, there are also performance metrics specific to the trained classifiers. For training purposes, the labeled data was split into three parts: a test set (20%) used for the final evaluation of the best model, a training set (72%, or 90% of the remaining 80%) that the model uses to learn underlying patterns and adjust its parameters, and a validation set (8%, or 10% of the 80%) used to calculate evaluation metrics after each epoch (i.e., one full cycle of the model processing the training data). Before the data was split into these three parts, I balanced the two labels (originally there were more correct than incorrect interpretations) to ensure that the model would not overfit to this class-imbalance.</p>
<p>During BERT training, I computed the training loss (sum of errors between model predictions and actual labels in the training set) and the validation loss (same for validation set). The best-performing model was selected based on the lowest validation loss. The model would have been trained on a maximum of 16 epochs, but training ended early if the model did not improve, as measured by the validation loss, for two epochs. In fact, the longest training was 12. For final evaluation, I computed the fraction of correctly predicted classes among all predicted cases of a class (precision), the fraction of correctly predicted classes among all actual cases of a class (recall), and their harmonic mean (F1 score), separately for each class. To summarize overall performance across the two classes, I calculated the unweighted average of the two F1 scores (macro-F1 score).</p>
</section>
<section id="software" class="level2">
<h2 data-anchor-id="software">2.3 Software</h2>
<p>All scripts for this thesis project were written in R [Version 4.5.0; <span class="citation" data-cites="rcoreteam25">Team (<a href="#ref-rcoreteam25" role="doc-biblioref">2025</a>)</span>] or Python [Version 3.12.10; <span class="citation" data-cites="python">Python Software Foundation (<a href="#ref-python" role="doc-biblioref">2025</a>)</span>].</p>
<p>In R, I used <em>papercheck</em> [Version 0.0.0.9049; <span class="citation" data-cites="R-papercheck">DeBruine and Lakens (<a href="#ref-R-papercheck" role="doc-biblioref">2025</a>)</span>] for accessing the 250 open access articles, preprocess them and for communication with the LLM, <em>readxl</em> [Version 1.4.5; <span class="citation" data-cites="R-readxl">Wickham and Bryan (<a href="#ref-R-readxl" role="doc-biblioref">2025</a>)</span>] to access Excel files in R, <em>psych</em> [Version 2.5.6; <span class="citation" data-cites="R-psych">William Revelle (<a href="#ref-R-psych" role="doc-biblioref">2025</a>)</span>] for calculating descriptive statistics, <em>tidyverse</em> [Version 2.0.0; <span class="citation" data-cites="R-tidyverse">Wickham et al. (<a href="#ref-R-tidyverse" role="doc-biblioref">2019</a>)</span>] for data preprocessing and visualization, and <em>flextable</em> [Version 0.9.9; <span class="citation" data-cites="R-flextable">Gohel and Skintzos (<a href="#ref-R-flextable" role="doc-biblioref">2025</a>)</span>], <em>magick</em> [Version 2.8.7; <span class="citation" data-cites="R-magick">Jeroen (<a href="#ref-R-magick" role="doc-biblioref">2025</a>)</span>], <em>papaja</em> [Version 0.1.3; <span class="citation" data-cites="R-papaja">Aust and Barth (<a href="#ref-R-papaja" role="doc-biblioref">2024</a>)</span>] and <em>showtext</em> [Version 0.9-7; <span class="citation" data-cites="R-showtext">Qiu and details. (<a href="#ref-R-showtext" role="doc-biblioref">2024</a>)</span>] to create APA-formatted tables.</p>
<p>The Python libraries used to train the BERT models can be found in this requirements file: LINK. [NOTE: They were just to many and apparently it’s less common to cite these compared to R packages, which is why its sometimes very tricky to actually get info on how to cite them. I’ll look into it later.]</p>
<p>All scripts and data to reproduce and use the trained BERT models (Python), analyse the results and validity checks (mostly R) and recreate this manuscript (Quarto Markdown in R Studio; I did change few formatting, not content, related things manually in the exported Word document) are available in this GitHub repository, together with instructions on how to set it up: LINK.</p>
<p>This thesis was not preregistered as no inferential statistical tests were performed.</p>
</section>
</section>
<section id="results" class="level1">
<h1>3 Results</h1>
<section id="detection-accuracy" class="level2">
<h2 data-anchor-id="detection-accuracy">3.1 Detection Accuracy</h2>
<p>Manually going through 25 articles from papercheck’s sample library I detected 179 statements with a nonsignificant <em>p</em> value in total. The automated RegEx search caught 130 (73 %) of these completely, and 6 partially (incompletely) due to extraction errors (e.g., because of pdf formatting like page breaks, figures or footnotes). It also ‘found’ 3 false positives in the sense that it extracted ‘statements’ from tables or figure notes or ones that were misclassified as coming from a results section. Note, however, that the large majority of the total 49 missed statements were due to specific ways of writing (or not writing) the <em>p</em> value: 8 were missed because the authors wrote ‘n.s.’ instead of the nonsignificant <em>p</em> value, and 31 were missed because the <em>p</em> value was written as ‘<span class="math inline">p_s</span>’. Without these two mistakes the overall agreement of automated and manual approach would have been 93 %.</p>
<p>Most of the other misses were due to pdf formatting issues like figures, tables, footnotes and page breaks or unusual characters inside the statement that interfered with the statement extraction (11 in total).<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
</section>
<section id="classification-performance" class="level2">
<h2 data-anchor-id="classification-performance">3.2 Classification Performance</h2>
<p><a href="#fig-2" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a> shows the training and validation loss curves for the three BERT models across their training. Standard BERT was trained for a total of 12 epochs before early stopping was triggered due to a lack of improvement in validation loss for two consecutive epochs. The model from epoch 10 was therefore selected as the best-performing version. Similarly, SciBERT and PubMedBERT achieved their best validation performance after epoch 4 and 5, respectively.</p>
<p>As shown in <a href="#fig-2" class="quarto-xref" aria-expanded="false">Figure&nbsp;1</a>, the training loss consistently decreased over time for all three models, as expected given that they were optimized to fit the training data. In contrast, the validation loss plateaued in all models at a certain point, indicating that further improvements in fitting the training data no longer translated into better performance on unseen data and may even signal the onset of overfitting. Notably, this plateau occurred later in the training of the standard BERT model, which may reflect its different pretraining on general English text compared to the domain-specific pretraining of SciBERT and PubMedBERT.</p>
<div id="fig-2" class="quarto-float quarto-figure quarto-figure-center FigureWithNote" data-apa-note="Curves of the training and validation loss of the three trained BERT models. The best models for regular BERT, SciBERT and PubMedBERT were chosen after epoch 10, 4, and 5, respectively, based on the minumum validation loss." alt="Curves of the training and validation loss of the three trained BERT models. The best models for regular BERT, SciBERT and PubMedBERT were chosen after epoch 10, 4, and 5, respectively, based on the minumum validation loss." prefix="" data-fignum="1" data-custom-style="FigureWithNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Training and Validation Loss Curve</p>
</div>
</figcaption>
<div aria-describedby="fig-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../data/model_performance/loss_curve/loss_combined.png" class="img-fluid figure-img" style="width:6in" data-apa-note="Curves of the training and validation loss of the three trained BERT models. The best models for regular BERT, SciBERT and PubMedBERT were chosen after epoch 10, 4, and 5, respectively, based on the minumum validation loss." alt="Curves of the training and validation loss of the three trained BERT models. The best models for regular BERT, SciBERT and PubMedBERT were chosen after epoch 10, 4, and 5, respectively, based on the minumum validation loss.">
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Curves of the training and validation loss of the three trained BERT models. The best models for regular BERT, SciBERT and PubMedBERT were chosen after epoch 10, 4, and 5, respectively, based on the minumum validation loss.</p>
</div>
<p>The different performance metrics are summarized in <a href="#tbl-model-performance" class="quarto-xref" aria-expanded="false">Table&nbsp;1</a>. As reflected in the macro F1 score, both SciBERT achieved the best overall performance in classifying correct and incorrect statements with a macro F1 score of .91. Standard BERT and PubMedBERT lagged slightly behind, with macro F1 scores of .89 and .87, respectively. All three models appear to be better at predicting correct statements then incorrect ones, reflected by the F1 score of the ‘correct’ class, with SciBERT scoring best (‘correct’ F1 score of .91). Similarly, in all models, recall was higher than precision in the ‘correct’ class, whereas the opposite pattern was visible in the ‘incorrect’ class, suggesting that the models tend to err on the side of overidentifying statements as correct rather than incorrect. In fact, the standard BERT model was just slightly better at reducing false negatives (at the cost of more false positives) in this test set (Precision in the ‘incorrect’ class: .91 vs.&nbsp;SciBERT’s .97). <a href="#fig-3" class="quarto-xref" aria-expanded="false">Figure&nbsp;2</a> reveals more of these sometimes subtle differences between the three models.</p>
<div class="cell FigureWithNote" data-apa-note="Table of precision, recall and F1 score per model and class." data-ft-align="left" prefix="" data-tblnum="1" data-custom-style="FigureWithNote">
<div id="tbl-model-performance" class="cell quarto-float quarto-figure quarto-figure-center" data-apa-note="Table of precision, recall and F1 score per model and class." data-tblnum="1" data-ft-align="left" prefix="">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;1</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Model Performance</p>
</div>
</figcaption>
<div aria-describedby="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-6eaf34b2{}.cl-6ea77b5a{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6eaa9844{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-6eaab766{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab770{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab771{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab77a{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 1.5pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab77b{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab77c{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab784{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab785{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 1.5pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab786{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab78e{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab78f{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab798{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab799{width:0.957in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab79a{width:0.642in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab79b{width:0.494in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6eaab7a2{width:0.617in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-6eaf34b2"><thead><tr style="overflow-wrap:break-word;"><th class="cl-6eaab766"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"> </span></p></th><th colspan="3" class="cl-6eaab770"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">BERT</span></p></th><th colspan="3" class="cl-6eaab770"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">SciBERT</span></p></th><th colspan="3" class="cl-6eaab770"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">PubMedBERT</span></p></th></tr><tr style="overflow-wrap:break-word;"><th class="cl-6eaab77b"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"> </span></p></th><th class="cl-6eaab77c"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Precision</span></p></th><th class="cl-6eaab784"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Recall</span></p></th><th class="cl-6eaab785"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">F1 score</span></p></th><th class="cl-6eaab77c"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Precision</span></p></th><th class="cl-6eaab784"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Recall</span></p></th><th class="cl-6eaab785"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">F1 score</span></p></th><th class="cl-6eaab77c"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Precision</span></p></th><th class="cl-6eaab784"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Recall</span></p></th><th class="cl-6eaab785"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">F1 score</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-6eaab786"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Correct Class</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.87</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.92</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.89</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.86</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.97</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.91</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.83</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.92</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.87</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6eaab786"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Incorrect Class</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.91</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.86</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.88</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.97</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.85</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.90</span></p></td><td class="cl-6eaab78e"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.91</span></p></td><td class="cl-6eaab78f"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.82</span></p></td><td class="cl-6eaab798"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.86</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6eaab799"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">Macro F1 score</span></p></td><td class="cl-6eaab79a"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab79b"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab7a2"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.89</span></p></td><td class="cl-6eaab79a"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab79b"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab7a2"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.91</span></p></td><td class="cl-6eaab79a"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab79b"><p class="cl-6eaa9844"><span class="cl-6ea77b5a"></span></p></td><td class="cl-6eaab7a2"><p class="cl-6eaa9844"><span class="cl-6ea77b5a">.87</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of precision, recall and F1 score per model and class.</p>
</div>
</div>
<div id="fig-3" class="quarto-float quarto-figure quarto-figure-center FigureWithNote" data-apa-note="Confusion matrices of the three trained BERT models." alt="Confusion matrices of the three trained BERT models." prefix="" data-fignum="2" data-custom-style="FigureWithNote">
<figure class="quarto-float quarto-float-fig figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-fig" id="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Figure&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Confusion Matrix</p>
</div>
</figcaption>
<div aria-describedby="fig-3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../data/model_performance/confusion_matrix/confusion_matrix_combined.png" class="img-fluid figure-img" style="width:6.5in" data-apa-note="Confusion matrices of the three trained BERT models." alt="Confusion matrices of the three trained BERT models.">
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Confusion matrices of the three trained BERT models.</p>
</div>
<p>Since SciBERT was the best, overall model, <a href="#tbl-false-classification" class="quarto-xref" aria-expanded="false">Table&nbsp;2</a> shows some of its incorrect predictions.</p>
<div class="cell FigureWithNote" data-apa-note="Examples for incorrect classifications of the trained SciBERT model on the test data." data-ft-align="left" prefix="" data-tblnum="2" data-custom-style="FigureWithNote">
<div id="tbl-false-classification" class="cell quarto-float quarto-figure quarto-figure-center" data-apa-note="Examples for incorrect classifications of the trained SciBERT model on the test data." data-tblnum="2" data-ft-align="left" prefix="">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-false-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;2</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Incorrect SciBERT Classifications</p>
</div>
</figcaption>
<div aria-describedby="tbl-false-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-6f3a3396{}.cl-6f3368ae{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6f361996{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-6f3635c0{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f3635ca{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f3635d4{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f3635d5{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f3635d6{width:1in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f3635de{width:5in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-6f3a3396"><thead><tr style="overflow-wrap:break-word;"><th class="cl-6f3635c0"><p class="cl-6f361996"><span class="cl-6f3368ae">Model Prediction</span></p></th><th class="cl-6f3635ca"><p class="cl-6f361996"><span class="cl-6f3368ae">Statement</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-6f3635d4"><p class="cl-6f361996"><span class="cl-6f3368ae">False Negative</span></p></td><td class="cl-6f3635d5"><p class="cl-6f361996"><span class="cl-6f3368ae">Although the sensitivity for the not-learned set was statistically comparable to the prelearning baseline, t(44) = 1.95, p = .162, d = 0.29, the learned set revealed significantly higher scores compared with both the not-learned set, t(44) = 2.56, p &lt; .04, d = 0.38, and the prelearning set, t(44) = 4.51, p &lt; .001, d = 0.67 (all comparisons performed with Bonferroni correction; see Fig. 3a).</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f3635d4"><p class="cl-6f361996"><span class="cl-6f3368ae">False Negative</span></p></td><td class="cl-6f3635d5"><p class="cl-6f361996"><span class="cl-6f3368ae">However, CS type did not interact significantly with the contrast between the uninformed and random groups; the uninformed group showed no better differentiation than the random group, F(1, 76) = 1.29, p = .26, 95% CI = [-0.16, 0.57].</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f3635d4"><p class="cl-6f361996"><span class="cl-6f3368ae">False Negative</span></p></td><td class="cl-6f3635d5"><p class="cl-6f361996"><span class="cl-6f3368ae">Gender, trait aggression, and endogenous testosterone did not affect these behavioral congruency effects on RTs and accuracy, and aggression and endogenous testosterone were not significantly correlated (r = .046, p = .45).</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f3635d6"><p class="cl-6f361996"><span class="cl-6f3368ae">False Positive</span></p></td><td class="cl-6f3635de"><p class="cl-6f361996"><span class="cl-6f3368ae">The main effect of illness recency did not meet our preregistered threshold (p &lt; .025)-recently ill: M = 661 ms, SD = 197; not recently ill: M = 626 ms, SD = 153, F(1, 400) = 4.23, Î· p 2 = .010, 90% CI = [.000, .039], p = .040-nor did the interaction between illness recency and face type (disfigured vs. typical), F(1, 400) = 1.87, Î· p 2 = .005, 90% CI = [.000, .027], p = .173.</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Examples for incorrect classifications of the trained SciBERT model on the test data.</p>
</div>
</div>
</section>
<section id="correction-evaluation" class="level2">
<h2 data-anchor-id="correction-evaluation">3.3 Correction Evaluation</h2>
<p>Of the 100 statements that the LLM was instructed to correct 85 were correct. Interestingly, 2 of the 20 already correct statements got turned incorrect by the LLM. 18, on the other hand, remained correct. Similarly, the LLM actually corrected 67 of the 80 incorrect statements, whereas 13 remained incorrect. Note, however, that the LLM was instructed to change (as much as necessary, but) as little as possible about the original statement. For some statements, this meant that they could not be corrected without major rephrasing. Examples for some bad/good corrections can be found in <a href="#tbl-LLM-corrections-1" class="quarto-xref" aria-expanded="false">Table&nbsp;3</a> and <a href="#tbl-LLM-corrections-2" class="quarto-xref" aria-expanded="false">Table&nbsp;4</a>, respectively.</p>
<div class="cell FigureWithNote" data-apa-note="Table of original and LLM-corrected statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect." data-ft-align="left" prefix="" data-tblnum="3" data-custom-style="FigureWithNote">
<div id="tbl-LLM-corrections-1" class="cell quarto-float quarto-figure quarto-figure-center" data-apa-note="Table of original and LLM-corrected statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect." data-tblnum="3" data-ft-align="left" prefix="">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-LLM-corrections-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;3</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Examples of Incorrect LLM Corrections</p>
</div>
</figcaption>
<div aria-describedby="tbl-LLM-corrections-1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-6f54080c{}.cl-6f4c3e4c{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6f500d6a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-6f500d74{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1.2;background-color:transparent;}.cl-6f5027dc{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f5027e6{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f5027e7{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f5027f0{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f5027f1{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f5027f2{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-6f54080c"><thead><tr style="overflow-wrap:break-word;"><th class="cl-6f5027dc"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">Example</span></p></th><th class="cl-6f5027dc"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">Statement Type</span></p></th><th class="cl-6f5027e6"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">Statement</span></p></th><th class="cl-6f5027dc"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">Label</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-6f5027e7"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">Example 1 to 1</span></p></td><td class="cl-6f5027e7"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">Original</span></p></td><td class="cl-6f5027f0"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">However, when the target was uncommitted, participants no longer preferred the seeker, p = .849, d = -0.03, rating both targets equally.</span></p></td><td class="cl-6f5027e7"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f5027e7"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">LLM-Corrected</span></p></td><td class="cl-6f5027f0"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">However, when the target was uncommitted, participants showed no significant preference for the seeker over the other target, p = .849, d = -0.03, rating both targets equally.</span></p></td><td class="cl-6f5027e7"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-6f5027f1"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">Example 0 to 1</span></p></td><td class="cl-6f5027e7"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">Original</span></p></td><td class="cl-6f5027f0"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">By contrast, leader narcissism levels were not significantly related to follower-perceived leader authority, b = 0.04, 95% CI = [-0.04, 0.13], β = 0.10, p = .304, and effectiveness, b = 0.04, 95% CI = [-0.06, 0.14], β = 0.08, p = .398.</span></p></td><td class="cl-6f5027e7"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f5027f1"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">LLM-Corrected</span></p></td><td class="cl-6f5027f2"><p class="cl-6f500d74"><span class="cl-6f4c3e4c">By contrast, leader narcissism levels were not significantly related to follower-perceived leader authority, b = 0.04, 95% CI = [-0.04, 0.13], Î² = 0.10, p = .304, and effectiveness, b = 0.04, 95% CI = [-0.06, 0.14], Î² = 0.08, p = .398, indicating that the relationship between leader narcissism and these outcomes may be negligible, but the data do not provide sufficient evidence to conclude that there is no relationship.</span></p></td><td class="cl-6f5027f1"><p class="cl-6f500d6a"><span class="cl-6f4c3e4c">1</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of original and LLM-corrected statements that were classified as incorrect. In the examples ‘0’ refers to correct and ‘1’ to incorrect.</p>
</div>
</div>
<div class="cell FigureWithNote" data-apa-note="Table of original and LLM-corrected statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect." data-ft-align="left" prefix="" data-tblnum="4" data-custom-style="FigureWithNote">
<div id="tbl-LLM-corrections-2" class="cell quarto-float quarto-figure quarto-figure-center" data-apa-note="Table of original and LLM-corrected statements that were classified as incorrect. In the examples '0' refers to correct and '1' to incorrect." data-tblnum="4" data-ft-align="left" prefix="">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-LLM-corrections-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="FigureTitle" data-custom-style="FigureTitle">
<p>Table&nbsp;4</p>
</div>
<div class="Caption" data-custom-style="Caption">
<p>Examples of Correct LLM Corrections</p>
</div>
</figcaption>
<div aria-describedby="tbl-LLM-corrections-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="tabwid"><style>.cl-6f67412e{}.cl-6f60a986{font-family:'Times New Roman';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-6f63569a{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-6f6356a4{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1.2;background-color:transparent;}.cl-6f63706c{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f637076{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f637077{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f637078{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f637080{width:0.7in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-6f637081{width:4in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing="true" class="cl-6f67412e"><thead><tr style="overflow-wrap:break-word;"><th class="cl-6f63706c"><p class="cl-6f63569a"><span class="cl-6f60a986">Example</span></p></th><th class="cl-6f63706c"><p class="cl-6f63569a"><span class="cl-6f60a986">Statement Type</span></p></th><th class="cl-6f637076"><p class="cl-6f63569a"><span class="cl-6f60a986">Statement</span></p></th><th class="cl-6f63706c"><p class="cl-6f63569a"><span class="cl-6f60a986">Label</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-6f637077"><p class="cl-6f6356a4"><span class="cl-6f60a986">Example 1 to 0</span></p></td><td class="cl-6f637077"><p class="cl-6f6356a4"><span class="cl-6f60a986">Original</span></p></td><td class="cl-6f637078"><p class="cl-6f6356a4"><span class="cl-6f60a986">Only in the twin sample did a lower age of onset predict higher levels of melody discrimination (β = -0.09, p = .23 in musicians; β = -0.05, p = .001 in twins).</span></p></td><td class="cl-6f637077"><p class="cl-6f63569a"><span class="cl-6f60a986">1</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f637077"><p class="cl-6f6356a4"><span class="cl-6f60a986">LLM-Corrected</span></p></td><td class="cl-6f637078"><p class="cl-6f6356a4"><span class="cl-6f60a986">Only in the twin sample was there a significant association between a lower age of onset and higher levels of melody discrimination (β = -0.09, p = .23 in musicians; β = -0.05, p = .001 in twins), whereas in musicians, the association was not statistically significant.</span></p></td><td class="cl-6f637077"><p class="cl-6f63569a"><span class="cl-6f60a986">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td rowspan="2" class="cl-6f637080"><p class="cl-6f6356a4"><span class="cl-6f60a986">Example 0 to 0</span></p></td><td class="cl-6f637077"><p class="cl-6f6356a4"><span class="cl-6f60a986">Original</span></p></td><td class="cl-6f637078"><p class="cl-6f6356a4"><span class="cl-6f60a986">The years-of-experience single effect was not significant (β = 0.001, 95% CI = [-0.07, 0.07], p = .976).</span></p></td><td class="cl-6f637077"><p class="cl-6f63569a"><span class="cl-6f60a986">0</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-6f637080"><p class="cl-6f6356a4"><span class="cl-6f60a986">LLM-Corrected</span></p></td><td class="cl-6f637081"><p class="cl-6f6356a4"><span class="cl-6f60a986">The years-of-experience single effect was not significant (β = 0.001, 95% CI = [-0.07, 0.07], p = .976), indicating that the data do not provide sufficient evidence to reject the null hypothesis of no effect.</span></p></td><td class="cl-6f637080"><p class="cl-6f63569a"><span class="cl-6f60a986">0</span></p></td></tr></tbody></table></div>
</div>
</div>
</figure>
</div>
<div class="FigureNote" data-custom-style="FigureNote">
<p><em>Note</em>. Table of original and LLM-corrected statements that were classified as incorrect. In the examples ‘0’ refers to correct and ‘1’ to incorrect.</p>
</div>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>4 Discussion</h1>
<section id="summary-of-key-results" class="level2">
<h2 data-anchor-id="summary-of-key-results">4.1 Summary of Key Results</h2>
<p>In this study, I developed and evaluated a three-step pipeline for automatically correcting misinterpretations of nonsignificant results as evidence for the absence of an effect. The approach combines rule-based RegEx searches for detecting candidate statements, fine-tuned BERT models for classification, and LLMs to generate corrected phrasings. While each step leaves room for improvement, the pipeline performed well and shows promise for broader applications beyond <em>p</em> value misinterpretations.</p>
<p>Crucially, the framework works effectively because each step is tailored to a specific subtask in the correction process. The RegEx-based detection offers a fast, systematic, and transparent way of reducing the volume of text needing NLP-based analysis. The BERT models provide a lightweight yet powerful solution for learning subtle language patterns. Finally, the LLM correction, while optional, enhances the user experience by offering useful rewording suggestions tailored to a specific correction task. This layered, hybrid structure makes the approach both flexible and scalable.</p>
<p>The RegEx-based statement detection phase demonstrated that simple, rule-based searches can effectively flag a large proportion of candidate interpretations. However, as the study revealed, several limitations remain. For example, statements that reported nonsignificance in a slightly different way (e.g., as “p = n.s.” or with subscripted ‘<span class="math inline">p_s</span>’ ) were missed. In some cases, odd formatting issues in pdfs made correct extraction impossible. These limitations highlight the need to continue refining the RegEx patterns and to explore better text extraction techniques.</p>
<p>Still, the classification results are particularly promising given the relatively small size of the manually labeled dataset (&lt; 1,000 examples, split into training, validation, and test sets). The strong performance likely reflects a certain regularity in how nonsignificance is (mis)interpreted in academic writing - commonly through the use of either ‘significant’ or ‘no effect’ (e.g., ‘there was no effect’, but also ‘groups did not differ’) terminology. While the training dataset was limited to statements extracted from Psychological Science articles (using the existing papercheck sample library), the results provide a solid baseline for expansion using more diverse sources and research domains.</p>
<p>The final correction step, generating corrections of the original statements, was the least developed but offers clear potential. The correction mechanism is optional, and the system performs well even without it. However, when prompted with a clear and narrow task, the LLaMA model used here provided helpful and context-sensitive rewriting suggestions. These suggestions can help users reframe statements in more statistically appropriate ways and reflect on their misinterpretations.</p>
</section>
<section id="limitations-and-challenges" class="level2">
<h2 data-anchor-id="limitations-and-challenges">4.2 Limitations and Challenges</h2>
<p>Despite the encouraging results, several limitations must be acknowledged. First, the pipeline components were evaluated independently rather than as a fully integrated system. While each step (detection, classification, correction) showed strong performance on its own, cascading errors in a full pipeline will likely reduce the end accuracy. This limitation must be addressed before the framework can be shared.</p>
<p>Second, the manual annotation of training data introduces inevitable subjectivity. While I made efforts to standardize labels - often consulting a statistics expert (my supervisor) on difficult or borderline cases - the classifications reflect my interpretation of what constitutes a misinterpretation. A reader might disagree with how some example statements in this article were labeled, and that is valid. Ideally, multiple annotators and inter-rater agreement metrics would improve the reliability and generalizability of the training data. However, the fact that the fine-tuned BERT models generalized well to unseen data suggests that the labeling was systematic and allowed the models to learn.</p>
<p>A more practical challenge involves managing the tradeoff between false positives and false negatives. The current models aim to balance both for optimal macro performance. However, in practice, different use cases may prioritize one over the other. For example, an individual researcher using the system to improve their writing may prefer fewer false negatives (i.e., catching as many problematic statements as possible), even at the cost of some false positives. Conversely, a meta-scientist analyzing prevalence trends of this misinterpretation may prioritize precision to avoid overestimating misinterpretations. This issue can be mitigated by allowing users to adjust the model’s decision threshold to fit their specific goals, something that will also be included in the framework’s rollout as part of a papercheck module.</p>
<p>Another limitation involves the narrow context in which statements are classified (a single sentence containing a nonsignificant <em>p</em> value). This limited scope means the model cannot account for broader contextual factors, such as whether authors conducted equivalence testing, reported Bayesian results, or provided qualifying language elsewhere. As noted earlier, this study provides a baseline approach intended for future expansion.</p>
</section>
<section id="practical-use-and-future-directions" class="level2">
<h2 data-anchor-id="practical-use-and-future-directions">4.3 Practical Use and Future Directions</h2>
<p>The pipeline described in this study will be integrated into the papercheck infrastructure as a new module for identifying potential misinterpretations of nonsignificant results. While not perfect, the current system is already useful and planned improvements like the ones discussed above will continue to increase its reliability.</p>
<p>Importantly, the step-wise structure of the approach makes it easy to adapt for other classification or correction tasks. For example, users could build their own custom classifiers to detect different types of reporting issues <span class="citation" data-cites="vanabkoude25">(see <a href="#ref-vanabkoude25" role="doc-biblioref">van Abkoude, 2025</a>, for an example of using BERT classifiers to classify different problematic use of causal language)</span>. In the context of meta science, these classifiers could also be trained with already collected, hand-labeled data <span class="citation" data-cites="aczel_etal18">(e.g., <a href="#ref-aczel_etal18" role="doc-biblioref">Aczel et al., 2018</a>)</span>.</p>
<p>Going forward, a key step in improving the pipeline’s general usefulness will be expanding both the context considered and the scope of what is being searched. In its current version, only single sentences from results sections that contain nonsignificant <em>p</em> values are analyzed. The long-term goal, however, is to evaluate entire passages or paragraphs related to a nonsignificant finding in the entire article, in order to capture the full context and provide more meaningful corrections. Achieving this will be essential for addressing the misinterpretation problem more comprehensively.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>5 Conclusion</h1>
<p>This study demonstrates that a hybrid rule-based and NLP-driven pipeline can effectively detect, classify, and correct a common statistical misinterpretation in scientific writing: interpreting nonsignificant results as evidence for the absence of an effect. Each step - statement detection, classification, and correction - performed well independently. The next step is to evaluate the pipeline as a fully automated system in real-world use cases. With further refinement, this framework has the potential to enhance both automated manuscript checks and large-scale meta-scientific analyses at scale.</p>
</section>
<section id="achknowledgement" class="level1">
<h1>Achknowledgement</h1>
<p>I want to thank Dr.&nbsp;Daniël Lakens for his constant support in conducting this thesis, for a lovely research stay to work on it. I thank my partner for her constant support, for pushing me when I felt down and for very helpful discussions on whether and how we should and should not use AI. I thank Prof.&nbsp;Dr.&nbsp;Maike Luhmann for letting me work on a meta-scientific project like this that is so close to my heart, even though it was a little out of her expertise. I thank Christian Sodano for very helpful discussions on machine learning and BERT models that prevented model training from being ‘algorithmic <em>p</em>-hacking’.</p>
<p>I want to thank Dr.&nbsp;Daniël Lakens for his constant support throughout this thesis and for a wonderful research stay that allowed me to work on it in person. I thank my partner for her unwavering support, for encouraging me when I felt discouraged, and for our insightful discussions on whether and how we should and should not use AI. I also thank Prof.&nbsp;Dr.&nbsp;Maike Luhmann for allowing me to pursue a meta-scientific project that is so close to my heart, even though it falls somewhat outside her area of expertise. Finally, I thank Christian Sodano for helpful discussions on machine learning and BERT models, which helped ensure that my model training did not turn into ‘algorithmic <em>p</em>-hacking’.</p>
</section>
<section id="references" class="level1">
<h1>References</h1>
<!-- References will auto-populate in the refs div below -->
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-aczel_etal18" class="csl-entry" role="listitem">
Aczel, B., Palfi, B., Szollosi, A., Kovacs, M., Szaszi, B., Szecsi, P., Zrubka, M., Gronau, Q. F., Van Den Bergh, D., &amp; Wagenmakers, E.-J. (2018). Quantifying <span>Support</span> for the <span>Null Hypothesis</span> in <span>Psychology</span>: <span>An Empirical Investigation</span>. <em>Advances in Methods and Practices in Psychological Science</em>, <em>1</em>(3), 357–366. <a href="https://doi.org/10.1177/2515245918773742">https://doi.org/10.1177/2515245918773742</a>
</div>
<div id="ref-amrhein_etal19" class="csl-entry" role="listitem">
Amrhein, V., Greenland, S., &amp; McShane, B. (2019). Scientists rise up against statistical significance. <em>Nature</em>, <em>567</em>(7748), 305–307. <a href="https://doi.org/10.1038/d41586-019-00857-9">https://doi.org/10.1038/d41586-019-00857-9</a>
</div>
<div id="ref-R-papaja" class="csl-entry" role="listitem">
Aust, F., &amp; Barth, M. (2024). <em><span class="nocase">papaja</span>: <span>Prepare</span> reproducible <span>APA</span> journal articles with <span>R Markdown</span></em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.papaja">https://doi.org/10.32614/CRAN.package.papaja</a>
</div>
<div id="ref-beltagy_etal19" class="csl-entry" role="listitem">
Beltagy, I., Lo, K., &amp; Cohan, A. (2019). <em><span>SciBERT</span>: <span>A Pretrained Language Model</span> for <span>Scientific Text</span></em>. <a href="https://doi.org/10.48550/ARXIV.1903.10676">https://doi.org/10.48550/ARXIV.1903.10676</a>
</div>
<div id="ref-R-papercheck" class="csl-entry" role="listitem">
DeBruine, L., &amp; Lakens, D. (2025). <em>Papercheck: <span>Check</span> scientific papers for best practices</em> [Manual].
</div>
<div id="ref-devlin_etal19" class="csl-entry" role="listitem">
Devlin, J., Chang, M.-W., Lee, K., &amp; Toutanova, K. (2019). <span>BERT</span>: <span class="nocase">Pre-training</span> of <span>Deep Bidirectional Transformers</span> for <span>Language Understanding</span>. <em>Proceedings of the 2019 <span>Conference</span> of the <span>North</span></em>, 4171–4186. <a href="https://doi.org/10.18653/v1/N19-1423">https://doi.org/10.18653/v1/N19-1423</a>
</div>
<div id="ref-edwards_etal63" class="csl-entry" role="listitem">
Edwards, W., Lindman, H., &amp; Savage, L. J. (1963). Bayesian statistical inference for psychological research. <em>Psychological Review</em>, <em>70</em>(3), 193–242. <a href="https://doi.org/10.1037/h0044139">https://doi.org/10.1037/h0044139</a>
</div>
<div id="ref-R-flextable" class="csl-entry" role="listitem">
Gohel, D., &amp; Skintzos, P. (2025). <em>Flextable: <span>Functions</span> for tabular reporting</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.flextable">https://doi.org/10.32614/CRAN.package.flextable</a>
</div>
<div id="ref-goodman08" class="csl-entry" role="listitem">
Goodman, S. (2008). A <span>Dirty Dozen</span>: <span>Twelve P-Value Misconceptions</span>. <em>Seminars in Hematology</em>, <em>45</em>(3), 135–140. <a href="https://doi.org/10.1053/j.seminhematol.2008.04.003">https://doi.org/10.1053/j.seminhematol.2008.04.003</a>
</div>
<div id="ref-greenland_etal16" class="csl-entry" role="listitem">
Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., &amp; Altman, D. G. (2016). Statistical tests, <span>P</span> values, confidence intervals, and power: A guide to misinterpretations. <em>European Journal of Epidemiology</em>, <em>31</em>(4), 337–350. <a href="https://doi.org/10.1007/s10654-016-0149-3">https://doi.org/10.1007/s10654-016-0149-3</a>
</div>
<div id="ref-gu_etal22" class="csl-entry" role="listitem">
Gu, Y., Tinn, R., Cheng, H., Lucas, M., Usuyama, N., Liu, X., Naumann, T., Gao, J., &amp; Poon, H. (2022). Domain-<span>Specific Language Model Pretraining</span> for <span>Biomedical Natural Language Processing</span>. <em>ACM Transactions on Computing for Healthcare</em>, <em>3</em>(1), 1–23. <a href="https://doi.org/10.1145/3458754">https://doi.org/10.1145/3458754</a>
</div>
<div id="ref-heathers_etal18" class="csl-entry" role="listitem">
Heathers, J. A., Anaya, J., Van Der Zee, T., &amp; Brown, N. J. (2018). <em>Recovering data from summary statistics: <span>Sample Parameter Reconstruction</span> via <span>Iterative TEchniques</span> (<span>SPRITE</span>)</em>. <a href="https://doi.org/10.7287/peerj.preprints.26968v1">https://doi.org/10.7287/peerj.preprints.26968v1</a>
</div>
<div id="ref-hoekstra_etal06" class="csl-entry" role="listitem">
Hoekstra, R., Finch, S., Kiers, H. A. L., &amp; Johnson, A. (2006). Probability as certainty: <span>Dichotomous</span> thinking and the misuse of p values. <em>Psychonomic Bulletin &amp; Review</em>, <em>13</em>(6), 1033–1037. <a href="https://doi.org/10.3758/BF03213921">https://doi.org/10.3758/BF03213921</a>
</div>
<div id="ref-isager_fitzgerald25" class="csl-entry" role="listitem">
Isager, P. M., &amp; Fitzgerald, J. (2025). <em>Three-<span>Sided Testing</span> to <span>Establish Practical Significance</span>: <span>A Tutorial</span></em>. <a href="https://doi.org/10.31234/osf.io/8y925">https://doi.org/10.31234/osf.io/8y925</a>
</div>
<div id="ref-R-magick" class="csl-entry" role="listitem">
Jeroen, O. (2025). <em>Magick: <span>Advanced Graphics</span> and <span>Image-Processing</span> in <span>R</span></em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.magick">https://doi.org/10.32614/CRAN.package.magick</a>
</div>
<div id="ref-lakens21" class="csl-entry" role="listitem">
Lakens, D. (2021). The <span>Practical Alternative</span> to the <span><em>p</em></span> <span>Value Is</span> the <span>Correctly Used</span> <span><em>p</em></span> <span>Value</span>. <em>Perspectives on Psychological Science</em>, <em>16</em>(3), 639–648. <a href="https://doi.org/10.1177/1745691620958012">https://doi.org/10.1177/1745691620958012</a>
</div>
<div id="ref-lakens_etal18" class="csl-entry" role="listitem">
Lakens, D., Adolfi, F. G., Albers, C. J., Anvari, F., Apps, M. A. J., Argamon, S. E., Baguley, T., Becker, R. B., Benning, S. D., Bradford, D. E., Buchanan, E. M., Caldwell, A. R., Van Calster, B., Carlsson, R., Chen, S.-C., Chung, B., Colling, L. J., Collins, G. S., Crook, Z., … Zwaan, R. A. (2018). Justify your alpha. <em>Nature Human Behaviour</em>, <em>2</em>(3), 168–171. <a href="https://doi.org/10.1038/s41562-018-0311-x">https://doi.org/10.1038/s41562-018-0311-x</a>
</div>
<div id="ref-mcshane_etal19" class="csl-entry" role="listitem">
McShane, B. B., Gal, D., Gelman, A., Robert, C., &amp; Tackett, J. L. (2019). Abandon <span>Statistical Significance</span>. <em>The American Statistician</em>, <em>73</em>(sup1), 235–245. <a href="https://doi.org/10.1080/00031305.2018.1527253">https://doi.org/10.1080/00031305.2018.1527253</a>
</div>
<div id="ref-murphy_etal25" class="csl-entry" role="listitem">
Murphy, S. L., Merz, R., Reimann, L.-E., &amp; Fernández, A. (2025). Nonsignificance misinterpreted as an effect’s absence in psychology: Prevalence and temporal analyses. <em>Royal Society Open Science</em>, <em>12</em>(3), 242167. <a href="https://doi.org/10.1098/rsos.242167">https://doi.org/10.1098/rsos.242167</a>
</div>
<div id="ref-nuijten_epskamp24" class="csl-entry" role="listitem">
Nuijten, M. B., &amp; Epskamp, S. (2024). <em>Statcheck: <span>Extract</span> statistics from articles and recompute p-values. <span>R</span> package version 1.5.0.</em> Web implementation at https://statcheck.io.
</div>
<div id="ref-python" class="csl-entry" role="listitem">
Python Software Foundation. (2025). <em>Python: A dynamic, open source programming language</em> [Manual]. Python Software Foundation.
</div>
<div id="ref-R-showtext" class="csl-entry" role="listitem">
Qiu, Y., &amp; details., authors/contributors. of the included software. S. file A. for. (2024). <em>Showtext: <span>Using</span> fonts more easily in <span>R</span> graphs</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.showtext">https://doi.org/10.32614/CRAN.package.showtext</a>
</div>
<div id="ref-schervish96" class="csl-entry" role="listitem">
Schervish, M. J. (1996). <span><em>P</em></span> <span>Values</span>: <span>What They</span> are and <span>What They</span> are <span>Not</span>. <em>The American Statistician</em>, <em>50</em>(3), 203–206. <a href="https://doi.org/10.1080/00031305.1996.10474380">https://doi.org/10.1080/00031305.1996.10474380</a>
</div>
<div id="ref-stillman19" class="csl-entry" role="listitem">
Stillman, D. (2019). <em>Retracted item notifications with <span>Retraction Watch</span> integration</em>. https://www.zotero.org/blog/retracted-item-notifications/.
</div>
<div id="ref-rcoreteam25" class="csl-entry" role="listitem">
Team, R. C. (2025). <em>R: <span>A Language</span> and <span>Environment</span> for <span>Statistical Computing</span></em> [Manual]. R Foundation for Statistical Computing.
</div>
<div id="ref-vanabkoude25" class="csl-entry" role="listitem">
van Abkoude, T. (2025). <em>Causal <span>Confusion</span>: <span>How LLMs Can Improve Causal Language</span> in <span>Research Communication</span></em> [Master's {{Thesis}}].
</div>
<div id="ref-wagenmakers07" class="csl-entry" role="listitem">
Wagenmakers, E.-J. (2007). A practical solution to the pervasive problems of <span><em>p</em></span> values. <em>Psychonomic Bulletin &amp; Review</em>, <em>14</em>(5), 779–804. <a href="https://doi.org/10.3758/BF03194105">https://doi.org/10.3758/BF03194105</a>
</div>
<div id="ref-R-tidyverse" class="csl-entry" role="listitem">
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the <span class="nocase">tidyverse</span>. <em>Journal of Open Source Software</em>, <em>4</em>(43), 1686. <a href="https://doi.org/10.21105/joss.01686">https://doi.org/10.21105/joss.01686</a>
</div>
<div id="ref-R-readxl" class="csl-entry" role="listitem">
Wickham, H., &amp; Bryan, J. (2025). <em>Readxl: <span>Read</span> excel files</em> [Manual]. <a href="https://doi.org/10.32614/CRAN.package.readxl">https://doi.org/10.32614/CRAN.package.readxl</a>
</div>
<div id="ref-R-psych" class="csl-entry" role="listitem">
William Revelle. (2025). <em>Psych: <span>Procedures</span> for psychological, psychometric, and personality research</em> [Manual]. Northwestern University.
</div>
</div>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>In a final tool, users will be able to set the alpha level they used themselves, thus allowing other levels than the conventional 5%.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>I could not find one statement that was extracted automatically in the artilce’s pdf. My current theory is that this was an artifact from when the pdf was compiled and might be from a different article even, once again highlighting how impractical the pdf format is in times of increasing automation.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>