{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e0f8a44",
   "metadata": {},
   "source": [
    "# Sentence Classification using BERT\n",
    "\n",
    "Code taken from: https://www.kaggle.com/code/akshat0007/bert-for-sequence-classification/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85161478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Checking for the GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79b36924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Checking for the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66dce4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# done once!\n",
    "\n",
    "\n",
    "# import wget\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "\n",
    "# # Unzipping the dataset\n",
    "# zip_path = './cola_public_1.1.zip'\n",
    "# extract_path = './'\n",
    "\n",
    "# if not os.path.exists('./cola_public/'):\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cab4b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raphael\\OneDrive\\RUB\\1_Master\\Masterarbeit\\2_Code_and_Data\\2025-07-05 - Train BERT with labeled_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4464cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples in balanced dataset: 278\n",
      "label\n",
      "1    139\n",
      "0    139\n",
      "Name: count, dtype: int64\n",
      "                                              sentence  label\n",
      "66   Finally, there was no significant interaction ...      0\n",
      "160  The congruency effect was significant in the a...      0\n",
      "147  We found the same pattern for RTs: A 7 (Positi...      0\n",
      "96   No significant gender differences emerged in a...      0\n",
      "90   In all these models, women were more likely to...      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(r\"C:\\Users\\Raphael\\OneDrive\\RUB\\1_Master\\Masterarbeit\\2_Code_and_Data\\2025-06-27 - labeled data_nonsig-with-pvalue/2025-06-28_labeled_data.xlsx\")\n",
    "\n",
    "# Drop rows with NA or label_strict == -99\n",
    "df = df.dropna(subset=['label_strict'])\n",
    "df = df[df['label_strict'] != -99]\n",
    "\n",
    "# Keep only correct (0) and incorrect (1) labels\n",
    "df = df[df['label_strict'].isin([0, 1])]\n",
    "\n",
    "# Create binary label column (same as label_strict)\n",
    "df['label'] = df['label_strict'].astype(int)\n",
    "\n",
    "# Rename your text column to 'sentence'\n",
    "# Replace 'statement_text' with the actual name if needed\n",
    "df['sentence'] = df['expanded']\n",
    "\n",
    "# Create a balanced subset:\n",
    "# - All incorrect (label == 1)\n",
    "# - Equal number of randomly sampled correct (label == 0)\n",
    "incorrect_df = df[df['label'] == 1]\n",
    "correct_df = df[df['label'] == 0].sample(n=incorrect_df.shape[0], random_state=42)\n",
    "\n",
    "# Combine and shuffle\n",
    "balanced_df = pd.concat([incorrect_df, correct_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print result summary\n",
    "print(f\"Total examples in balanced dataset: {balanced_df.shape[0]}\")\n",
    "print(balanced_df['label'].value_counts())\n",
    "\n",
    "# Show 5 random rows\n",
    "print(balanced_df.sample(5)[['sentence', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc13d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets (80/20)\n",
    "train_df, test_df = train_test_split(\n",
    "    balanced_df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=balanced_df['label']  # Ensures label balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30227b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "32f66042-cf75-4f8f-a453-8535ebc9efa8",
       "rows": [
        [
         "164",
         "There was no significant interaction between participant height and opponent height, Wald Ï‡ 2 (1) = 0.38, b = 0.042, SE = 0.068, 95% CI = [-0.091, 0.174], p = .540 (QICc = 203.85).",
         "0"
        ],
        [
         "87",
         "There was no First Fixation Ã— Expected Value interaction, b = -0.54, SE = 0.74, z = -0.72, p = .47.",
         "1"
        ],
        [
         "25",
         "In contrast, non-White AI faces (left side of Fig. 2a) were judged as human at around chance levels, M non-White-AI = 50.5%, t(314) = 0.41, p = .682, d = 0.02, 95% CI = [-0.09, 0.13], which did not differ significantly from how often non-White human faces were judged to be human, versus M non-White-human = 51.3%, t(314) = 0.74, p = .461, d = 0.04, 95% CI = [-0.07, 0.15].",
         "0"
        ],
        [
         "115",
         "Performance was fastest for the biggest and smallest positions compared with the inner positions, with no significant difference between the outer two positions, t(116) = -1.417, p = .62, and was slightly faster for sets with one dot, M = 970, SE = 30.60, 95% CI = [907, 1,032], compared with three dots, M = 1,015, SE = 30.6, 95% CI = [953, 1,077], and five dots, M = 1,004, SE = 30.6, 95% CI = 942, 1,066].",
         "0"
        ],
        [
         "150",
         "Cortisol concentrations were comparable at baseline, t(55) = 1.01, p = .317, d = 0.27, but significantly elevated in the stress group relative to the control group both 30 min after the treatment, t(55) = 3.55, p corr = .003, d = 0.94, and 45 min after the treatment, t(55) = 2.52, p corr = .045, d = 0.67 (Table 1).",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>There was no significant interaction between p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>There was no First Fixation Ã— Expected Value ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>In contrast, non-White AI faces (left side of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Performance was fastest for the biggest and sm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Cortisol concentrations were comparable at bas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label\n",
       "164  There was no significant interaction between p...      0\n",
       "87   There was no First Fixation Ã— Expected Value ...      1\n",
       "25   In contrast, non-White AI faces (left side of ...      0\n",
       "115  Performance was fastest for the biggest and sm...      0\n",
       "150  Cortisol concentrations were comparable at bas...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another random 5 examples from training set\n",
    "train_df.sample(5)[['sentence', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab5f7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the lists of sentences and their labels.\n",
    "train_sentences = train_df.sentence.values\n",
    "train_labels = train_df.label.values\n",
    "\n",
    "test_sentences = test_df.sentence.values\n",
    "test_labels = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26c661e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78edfdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  A 7 (Position) Ã— 4 (Ratio) repeated-measures ANOVA with RT as the dependent variable showed a significant main effect of position, F(4, 116) = 16.45, p < .001, f = 0.75, a nonsignificant main effect of ratio, F(3, 87) = 1.752, p = .16, f = 0.25, and a nonsignificant interaction, F(12, 348) = 1.421, p = .154, f = 0.22, with participants again faster to find the shortest and longest lines.\n",
      "Tokenized:  ['a', '7', '(', 'position', ')', 'a', '—', '4', '(', 'ratio', ')', 'repeated', '-', 'measures', 'an', '##ova', 'with', 'rt', 'as', 'the', 'dependent', 'variable', 'showed', 'a', 'significant', 'main', 'effect', 'of', 'position', ',', 'f', '(', '4', ',', '116', ')', '=', '16', '.', '45', ',', 'p', '<', '.', '001', ',', 'f', '=', '0', '.', '75', ',', 'a', 'non', '##si', '##gni', '##fi', '##can', '##t', 'main', 'effect', 'of', 'ratio', ',', 'f', '(', '3', ',', '87', ')', '=', '1', '.', '75', '##2', ',', 'p', '=', '.', '16', ',', 'f', '=', '0', '.', '25', ',', 'and', 'a', 'non', '##si', '##gni', '##fi', '##can', '##t', 'interaction', ',', 'f', '(', '12', ',', '34', '##8', ')', '=', '1', '.', '421', ',', 'p', '=', '.', '154', ',', 'f', '=', '0', '.', '22', ',', 'with', 'participants', 'again', 'faster', 'to', 'find', 'the', 'shortest', 'and', 'longest', 'lines', '.']\n",
      "Token IDs:  [1037, 1021, 1006, 2597, 1007, 1037, 1517, 1018, 1006, 6463, 1007, 5567, 1011, 5761, 2019, 7103, 2007, 19387, 2004, 1996, 7790, 8023, 3662, 1037, 3278, 2364, 3466, 1997, 2597, 1010, 1042, 1006, 1018, 1010, 12904, 1007, 1027, 2385, 1012, 3429, 1010, 1052, 1026, 1012, 25604, 1010, 1042, 1027, 1014, 1012, 4293, 1010, 1037, 2512, 5332, 29076, 8873, 9336, 2102, 2364, 3466, 1997, 6463, 1010, 1042, 1006, 1017, 1010, 6584, 1007, 1027, 1015, 1012, 4293, 2475, 1010, 1052, 1027, 1012, 2385, 1010, 1042, 1027, 1014, 1012, 2423, 1010, 1998, 1037, 2512, 5332, 29076, 8873, 9336, 2102, 8290, 1010, 1042, 1006, 2260, 1010, 4090, 2620, 1007, 1027, 1015, 1012, 29403, 1010, 1052, 1027, 1012, 16666, 1010, 1042, 1027, 1014, 1012, 2570, 1010, 2007, 6818, 2153, 5514, 2000, 2424, 1996, 20047, 1998, 6493, 3210, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', train_sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_sentences[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e2b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  A 7 (Position) Ã— 4 (Ratio) repeated-measures ANOVA with RT as the dependent variable showed a significant main effect of position, F(4, 116) = 16.45, p < .001, f = 0.75, a nonsignificant main effect of ratio, F(3, 87) = 1.752, p = .16, f = 0.25, and a nonsignificant interaction, F(12, 348) = 1.421, p = .154, f = 0.22, with participants again faster to find the shortest and longest lines.\n",
      "Token IDs: [101, 1037, 1021, 1006, 2597, 1007, 1037, 1517, 1018, 1006, 6463, 1007, 5567, 1011, 5761, 2019, 7103, 2007, 19387, 2004, 1996, 7790, 8023, 3662, 1037, 3278, 2364, 3466, 1997, 2597, 1010, 1042, 1006, 1018, 1010, 12904, 1007, 1027, 2385, 1012, 3429, 1010, 1052, 1026, 1012, 25604, 1010, 1042, 1027, 1014, 1012, 4293, 1010, 1037, 2512, 5332, 29076, 8873, 9336, 2102, 2364, 3466, 1997, 6463, 1010, 1042, 1006, 1017, 1010, 6584, 1007, 1027, 1015, 1012, 4293, 2475, 1010, 1052, 1027, 1012, 2385, 1010, 1042, 1027, 1014, 1012, 2423, 1010, 1998, 1037, 2512, 5332, 29076, 8873, 9336, 2102, 8290, 1010, 1042, 1006, 2260, 1010, 4090, 2620, 1007, 1027, 1015, 1012, 29403, 1010, 1052, 1027, 1012, 16666, 1010, 1042, 1027, 1014, 1012, 2570, 1010, 2007, 6818, 2153, 5514, 2000, 2424, 1996, 20047, 1998, 6493, 3210, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in train_sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', train_sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63dcdbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  277\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6a7aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use some utility function from tensorflow(Tensorflow was my first crush)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_LEN = 64\n",
    "\n",
    "# Helper function\n",
    "def tokenize_and_pad(sentences, tokenizer, max_len):\n",
    "    input_ids = []\n",
    "    for sent in sentences:\n",
    "        encoded = tokenizer.encode(sent, add_special_tokens=True, truncation=True, max_length=max_len)\n",
    "        input_ids.append(encoded)\n",
    "    input_ids = pad_sequences(input_ids, maxlen=max_len, padding='post', truncating='post')\n",
    "    attention_masks = [[int(token_id > 0) for token_id in seq] for seq in input_ids]\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "# Tokenize train and test\n",
    "train_input_ids, train_attention_masks = tokenize_and_pad(train_sentences, tokenizer, MAX_LEN)\n",
    "test_input_ids, test_attention_masks = tokenize_and_pad(test_sentences, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99c4fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd2afd65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [222, 199]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Split train into train/validation\u001b[39;00m\n\u001b[32m      6\u001b[39m train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n\u001b[32m      7\u001b[39m     train_input_ids, train_labels, test_size=\u001b[32m0.1\u001b[39m, random_state=\u001b[32m2018\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_masks, validation_masks, _, _ = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_attention_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2018\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2848\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2848\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2851\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2852\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2853\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:532\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [222, 199]"
     ]
    }
   ],
   "source": [
    "# We will call the train_test_split() function from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split train into train/validation\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    train_input_ids, train_labels, test_size=0.1, random_state=2018)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    train_attention_masks, train_labels, test_size=0.1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe89aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the input data to the tensor , which can be fed to the model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#Creating the DataLoader which will help us to load data into the GPU/CPU\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the pre-trained BERT model from huggingface library\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels = 2,   \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, )\n",
    "\n",
    "# Teeling the model to run on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW is an optimizer which is a Adam Optimzier with weight-decay-fix\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f37e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x191832d54c0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333699dc",
   "metadata": {},
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30788254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96008642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the helper function to have a watch on elapsed time\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed68c8",
   "metadata": {},
   "source": [
    "## Let's start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebce05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.71\n",
      "  Training epoch took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.58\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epoch took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epoch took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.48\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.63\n",
      "  Training epoch took: 0:00:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.55\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7028781308068169, 0.680268128712972, 0.6705409222178988, 0.6609748270776536]\n"
     ]
    }
   ],
   "source": [
    "print(loss_values) #Having a view of stored loss values in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the test data and applying the same preprocessing techniques which we performed on the train data\n",
    "import pandas as pd\n",
    "\n",
    "prediction_inputs = torch.tensor(test_input_ids)\n",
    "prediction_masks = torch.tensor(test_attention_masks)\n",
    "prediction_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 278 test sentences...\n"
     ]
    }
   ],
   "source": [
    "#Evaluating our model on the test set\n",
    "\n",
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ab160",
   "metadata": {},
   "source": [
    "We will use Matthews Correlation Coefficient(MCC) to evaluate our model. MCC is used in many areas of Natural Language Processing. Also, it's a great metric to be used for imbalanced dataset\n",
    "\n",
    "Link: https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b453d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 139 of 278 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6421417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b5111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.510\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eba3cb7",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da00fa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[128  11]\n",
      " [ 62  77]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.67      0.92      0.78       139\n",
      "     class 1       0.88      0.55      0.68       139\n",
      "\n",
      "    accuracy                           0.74       278\n",
      "   macro avg       0.77      0.74      0.73       278\n",
      "weighted avg       0.77      0.74      0.73       278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Step 1: Convert logits to predicted class labels\n",
    "# Each element in predictions is a batch of logits\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "predicted_labels = np.argmax(flat_predictions, axis=1)\n",
    "\n",
    "# Step 2: Flatten the true labels\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Step 3: Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(flat_true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optional: Print a classification report (includes precision, recall, F1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(flat_true_labels, predicted_labels, target_names=[\"class 0\", \"class 1\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ad6d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming flat_true_labels and predicted_labels are defined as before\n",
    "\n",
    "conf_matrix = confusion_matrix(flat_true_labels, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"Predicted 0\", \"Predicted 1\"],\n",
    "            yticklabels=[\"Actual 0\", \"Actual 1\"])\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2025-07-05 - Train BERT with labeled_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
